{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hEZyBl5mDJI"
      },
      "source": [
        "# Marketing Analytics Team 4 Emily in Paris Notebook\n",
        "\n",
        "### Team members:\n",
        "- Jenny Dong, Helen Lin, Michelle Park, Yani Iben\n",
        "\n",
        "**Project objective**\n",
        "- Increasing Emily in Paris audience viewership for Season 5, as the production team has observed declining viewership and ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHSxaJ82gGWY"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7gflVGAkO3k",
        "outputId": "7eb216d1-915e-4ff6-e557-78edece350ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nrclex\n",
            "  Downloading NRCLex-4.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (from nrclex) (0.17.1)\n",
            "INFO: pip is looking at multiple versions of nrclex to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading NRCLex-3.0.0.tar.gz (396 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob->nrclex) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (4.66.6)\n",
            "Building wheels for collected packages: nrclex\n",
            "  Building wheel for nrclex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nrclex: filename=NRCLex-3.0.0-py3-none-any.whl size=43308 sha256=b52d7afc631c14a90b170071c52a40fdf2e42a1f47fc782bf638714c9811028a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/10/44/6abfb1234298806a145fd6bcaec8cbc712e88dd1cd6cb242fa\n",
            "Successfully built nrclex\n",
            "Installing collected packages: nrclex\n",
            "Successfully installed nrclex-3.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install nrclex\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TpTkEfxx9nW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "# Python API libraries\n",
        "import requests\n",
        "# Scrapying Library\n",
        "from bs4 import BeautifulSoup\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import gutenberg\n",
        "# Ensure you have NLTK's Gutenberg corpus\n",
        "import nltk\n",
        "\n",
        "# Topic modeling, Sentiment Analysis, & Emotion Analysis\n",
        "from sklearn.feature_extraction.text import CountVectorizer # Data Cleaning\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import re\n",
        "from nrclex import NRCLex # Emotion Analysis\n",
        "from textblob import TextBlob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH_m93Bo90nE"
      },
      "source": [
        "# Topic Modeling, Sentiment Analysis, & Emotion Analysis\n",
        "\n",
        "\n",
        "*   In this section, we will perform topic modeling on the transcripts of each episode of all 4 existing seasons of Emily in Paris as well as sentiment & emotion analysis to showcase...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVK1ZhYALmAx"
      },
      "source": [
        "## Season 1 Episode 1: Emily in Paris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4AQAXEHI6ZY",
        "outputId": "6c39c4ce-bfff-4153-9561-d4dd865c3170"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'S1E1.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d6704db9065c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load transcript text from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'S1E1.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtranscript_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'S1E1.txt'"
          ]
        }
      ],
      "source": [
        "# S1E1\n",
        "\n",
        "# Load transcript text from file\n",
        "with open('S1E1.txt', 'r', encoding='utf-8') as file:\n",
        "    transcript_text = file.read()\n",
        "\n",
        "# Step 1: Data Cleaning\n",
        "# Remove line breaks, punctuation, and convert to lowercase\n",
        "cleaned_text = re.sub(r'\\n+', ' ', transcript_text)  # Remove extra line breaks\n",
        "cleaned_text = re.sub(r'[-]', '', cleaned_text)  # Remove dashes\n",
        "cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', cleaned_text)  # Remove non-alphabetical characters\n",
        "cleaned_text = cleaned_text.lower()  # Convert to lowercase\n",
        "\n",
        "# Define common English stopwords\n",
        "stop_words = {\n",
        "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
        "    \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\n",
        "    \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\",\n",
        "    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\",\n",
        "    \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\",\n",
        "    \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\",\n",
        "    \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\",\n",
        "    \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\",\n",
        "    \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\",\n",
        "    \"now\", \"httpstranscriptsforeverdreamingorgviewtopicphpt\", \"httpstranscriptsforeverdreamingorg\"\n",
        "}\n",
        "\n",
        "# Tokenize manually and remove stopwords\n",
        "tokens = cleaned_text.split()\n",
        "tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "cleaned_text_processed = ' '.join(tokens)\n",
        "\n",
        "# Step 2: Topic Modeling with LDA\n",
        "# Vectorize the text\n",
        "vectorizer = CountVectorizer(max_df=1.0, min_df=1)\n",
        "doc_term_matrix = vectorizer.fit_transform([cleaned_text_processed])\n",
        "\n",
        "# Apply LDA for topic modeling\n",
        "lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
        "lda_model.fit(doc_term_matrix)\n",
        "\n",
        "# Extract top words for each topic\n",
        "topics = {}\n",
        "for idx, topic in enumerate(lda_model.components_):\n",
        "    topic_words = [vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]]\n",
        "    topics[f'Topic {idx + 1}'] = topic_words\n",
        "\n",
        "# Display topics as DataFrame\n",
        "topics_df = pd.DataFrame(topics)\n",
        "print(topics_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQHOITGfNkzF"
      },
      "source": [
        "Topic 1: Theme: Normandy and Relaxation\n",
        "\n",
        "* Key words: \"normandy,\" \"holiday,\" \"hope,\" \"hot,\" \"hours,\" \"housekeeper\"\n",
        "* Interpretation: This topic could be related to vacationing or relaxation in Normandy. Words like \"holiday,\" \"hours,\" and \"housekeeper\" suggest a setting where people are taking time off, potentially involving travel or accommodations.\n",
        "\n",
        "Topic 2: Theme: Normandy and Interactions\n",
        "* Key words: \"normandy,\" \"holiday,\" \"hope,\" \"hot,\" \"housekeeper,\" \"huh\"\n",
        "* Interpretation: This topic might also focus on Normandy but emphasizes interactions or conversations. Words like \"honestly,\" \"huh,\" and \"hope\" indicate casual dialogues or interpersonal exchanges.\n",
        "\n",
        "Topic 3: Theme: French Culture and Encounters\n",
        "* Key words: \"yes,\" \"like,\" \"ah,\" \"well,\" \"emily,\" \"paris,\" \"french\"\n",
        "* Interpretation: This topic likely centers around cultural experiences or encounters in France. Words like \"paris,\" \"french,\" and \"emily\" suggest that this topic covers Emily's interactions and observations of French culture or lifestyle.\n",
        "\n",
        "Topic 4: Theme: Travel or Vacation in Normandy\n",
        "* Key words: \"normandy,\" \"holiday,\" \"hope,\" \"hot,\" \"housekeeper,\" \"home\"\n",
        "* Interpretation: This topic could again relate to travel or vacation, specifically in Normandy. Words like \"holiday,\" \"hope,\" and \"home\" suggest themes of visiting or spending time in a particular place.\n",
        "\n",
        "Topic 5: Theme: Accommodation and Time Off\n",
        "* Key words: \"normandy,\" \"holiday,\" \"hope,\" \"hot,\" \"housekeeper,\" \"home,\" \"hours\"\n",
        "* Interpretation: This topic likely focuses on accommodation and relaxation, possibly highlighting themes of staying in Normandy, perhaps with mentions of holiday homes or rentals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9BjRZEmJR5_",
        "outputId": "50b5e2b8-3537-41a7-d065-e0cd698640a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sentiment Analysis Summary:\n",
            "Average Sentiment Score: 0.02\n",
            "Positive Lines: 115\n",
            "Negative Lines: 64\n",
            "Neutral Lines: 913\n"
          ]
        }
      ],
      "source": [
        "# S1 E1\n",
        "\n",
        "# Step 3: Sentiment Analysis\n",
        "# Split the transcript into individual lines for analysis\n",
        "lines = transcript_text.split('\\n')\n",
        "\n",
        "# Analyze sentiment for each line\n",
        "sentiments = []\n",
        "for line in lines:\n",
        "    blob = TextBlob(line)\n",
        "    sentiment_score = blob.sentiment.polarity\n",
        "    sentiments.append(sentiment_score)\n",
        "\n",
        "# Calculate overall sentiment statistics\n",
        "average_sentiment = sum(sentiments) / len(sentiments)\n",
        "positive_lines = sum(1 for score in sentiments if score > 0)\n",
        "negative_lines = sum(1 for score in sentiments if score < 0)\n",
        "neutral_lines = sum(1 for score in sentiments if score == 0)\n",
        "\n",
        "# Display sentiment summary\n",
        "print(\"\\nSentiment Analysis Summary:\")\n",
        "print(f\"Average Sentiment Score: {average_sentiment:.2f}\")\n",
        "print(f\"Positive Lines: {positive_lines}\")\n",
        "print(f\"Negative Lines: {negative_lines}\")\n",
        "print(f\"Neutral Lines: {neutral_lines}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r1UVgi0TMLyL",
        "outputId": "72d96fb2-9ab6-4226-d169-0a42b96de577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n"
          ]
        },
        {
          "ename": "MissingCorpusError",
          "evalue": "\nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/tokenizers.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m'''Return a list of sentences.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_punkt_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPunktTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0mPunktSentenceTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mload_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m         \u001b[0mlang_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt_tab/{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_punkt_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMissingCorpusError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0271f823fd5e>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Step 2: Perform Emotion Analysis on the entire transcript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Use NRCLex for emotion analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0memotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNRCLex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Step 3: Aggregate emotion results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nrclex.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   2871\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m         \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2873\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2874\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2875\u001b[0m         \u001b[0mbuild_word_affect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/blob.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mWordList\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mWordList\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mword\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \"\"\"\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWordList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_punc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/tokenizers.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, include_punc, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         _word_tokenizer.itokenize(sentence, include_punc=include_punc,\n\u001b[1;32m     72\u001b[0m                                 *args, **kwargs)\n\u001b[0;32m---> 73\u001b[0;31m         for sentence in sent_tokenize(text))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/base.py\u001b[0m in \u001b[0;36mitokenize\u001b[0;34m(self, text, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m##### SENTIMENT ANALYZERS ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingCorpusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMissingCorpusError\u001b[0m: \nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n"
          ]
        }
      ],
      "source": [
        "# Load transcript text from file\n",
        "with open('S1E1.txt', 'r', encoding='utf-8') as file:\n",
        "    transcript_text = file.read()\n",
        "# Step 1: Clean and prepare text\n",
        "# Remove character names and extra information, keeping only dialogue\n",
        "cleaned_text = re.sub(r'^\\s*([A-Za-z]+):\\s*', '', transcript_text, flags=re.MULTILINE)\n",
        "\n",
        "# Step 2: Perform Emotion Analysis on the entire transcript\n",
        "# Use NRCLex for emotion analysis\n",
        "emotion = NRCLex(cleaned_text)\n",
        "\n",
        "# Step 3: Aggregate emotion results\n",
        "emotion_counts = emotion.raw_emotion_scores\n",
        "\n",
        "# Convert results to DataFrame for easy viewing\n",
        "emotion_df = pd.DataFrame(list(emotion_counts.items()), columns=['Emotion', 'Count'])\n",
        "emotion_df = emotion_df.sort_values(by='Count', ascending=False)\n",
        "\n",
        "# Display the emotion analysis result\n",
        "print(\"Emotion Analysis of S1E1 Transcript:\")\n",
        "print(emotion_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K2vU5IwOiQn"
      },
      "source": [
        "**Summary of S1E1**:\n",
        "\n",
        "* Sentiment:\n",
        "* Emotion:\n",
        "* Maybe add visualization as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5-WlxaFLuzd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pPPhlVHOB6p"
      },
      "source": [
        "## Season 1 Episode 2: Male Female"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h-HAyeGONQl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hojxDNq2-Zhm"
      },
      "source": [
        "# Time Series Regression\n",
        "\n",
        "*   In this section, we will train a decision tree regression model (bagging/random forest if needed) for predicting the rating of the episodes.\n",
        "*   We will use ChatGPT to create a few fictitious episodes of season 5 and use those to showcase how different topics discussed in each episodes are associated with ratings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQINE8-WVZil"
      },
      "source": [
        "### **Below are example code for time series predictive modeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWEDhLOSVZTb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "8a6dcb17-fea8-4f3b-eeda-65c979cee4fd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'emily_in_paris_features.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-40f281ac9f22>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"emily_in_paris_features.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Features and target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'emily_in_paris_features.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"emily_in_paris_features.csv\")\n",
        "\n",
        "# Features and target\n",
        "X = data[['Sentiment_Polarity', 'Sentiment_Subjectivity', 'Joy', 'Anger', 'Sadness', 'Episode_Number', 'Season']]\n",
        "y = data['Rating']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)  # Maintain temporal order\n",
        "\n",
        "# Train a regression model\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
        "\n",
        "# Predict season 5 ratings\n",
        "season_5_features = pd.DataFrame({\n",
        "    # Use sentiment and emotion averages from previous seasons or simulated values\n",
        "    'Sentiment_Polarity': [0.3] * 10,\n",
        "    'Sentiment_Subjectivity': [0.6] * 10,\n",
        "    'Joy': [0.7] * 10,\n",
        "    'Anger': [0.2] * 10,\n",
        "    'Sadness': [0.1] * 10,\n",
        "    'Episode_Number': list(range(1, 11)),\n",
        "    'Season': [5] * 10\n",
        "})\n",
        "season_5_ratings = model.predict(season_5_features)\n",
        "print(\"Predicted Ratings for Season 5:\", season_5_ratings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld3YtKYX-ZPw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ebi_B7Umalw"
      },
      "source": [
        "# Visualization   \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67ZKBHBsmhML"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1: Time Series"
      ],
      "metadata": {
        "id": "wagBIlLd06tB"
      }
    },
    {
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer  # Import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'EIPData.csv'  # Replace with your file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Select features and target\n",
        "emotion_features = [\"Positive\", \"Trust\", \"Joy\", \"Anticipation\", \"Negative\",\n",
        "                    \"Surprise\", \"Sadness\", \"Fear\", \"Anger\", \"Disgust\"]\n",
        "X = data[emotion_features] # Keep X as a DataFrame\n",
        "y = data['IMDB ratings (out of 10)']  # Target variable as Series\n",
        "\n",
        "\n",
        "# Add lagged features (time series component)\n",
        "for lag in range(1, 5):  # Lag of 1 to 3 episodes\n",
        "    lagged_features = X.shift(lag)  # Shift features by 'lag' steps\n",
        "    lagged_features.columns = [f\"{col}_lag{lag}\" for col in lagged_features.columns]\n",
        "    X = pd.concat([X, lagged_features], axis=1)\n",
        "\n",
        "# Drop rows with NaN values caused by lagging\n",
        "X = X.iloc[3:]\n",
        "y = y.iloc[3:]\n",
        "\n",
        "# Impute missing values using SimpleImputer\n",
        "# Strategy can be 'mean', 'median', 'most_frequent', or 'constant'\n",
        "imputer = SimpleImputer(strategy='mean')  # Create an imputer instance\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns) # Convert imputed data back to DataFrame\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=False)\n",
        "\n",
        "# Train a Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Display results\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R^2 Score: {r2:.2f}\")\n",
        "\n",
        "# Feature Importance (coefficients)\n",
        "feature_importance = pd.Series(model.coef_, index=X_train.columns).sort_values(ascending=False) # Now X_train has columns\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NEqTmkVhU1C",
        "outputId": "02c26cfb-a1f9-42cb-9b95-962e302f756b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.43\n",
            "R^2 Score: -0.64\n",
            "\n",
            "Feature Importance:\n",
            "Joy                                 0.002951\n",
            "Fear_lag2                           0.002539\n",
            "Surprise                            0.002434\n",
            "Anger_lag2_lag3_lag4                0.002418\n",
            "Positive_lag1_lag2_lag3_lag4        0.002118\n",
            "Negative_lag1_lag2_lag3_lag4        0.002047\n",
            "Sadness_lag2_lag3_lag4              0.001777\n",
            "Disgust_lag1_lag3                   0.001718\n",
            "Disgust_lag4                        0.001718\n",
            "Fear_lag1_lag3_lag4                 0.001692\n",
            "Anger_lag1_lag3                     0.001648\n",
            "Anger_lag4                          0.001648\n",
            "Disgust_lag1_lag2_lag3              0.001586\n",
            "Disgust_lag2_lag4                   0.001586\n",
            "Anger_lag2                          0.001531\n",
            "Disgust_lag2_lag3_lag4              0.001428\n",
            "Trust                               0.001415\n",
            "Sadness_lag2                        0.001358\n",
            "Disgust_lag3_lag4                   0.001313\n",
            "Disgust_lag1_lag2_lag4              0.001313\n",
            "Negative_lag1_lag3                  0.001271\n",
            "Negative_lag4                       0.001271\n",
            "Trust_lag2_lag3                     0.001262\n",
            "Trust_lag1_lag4                     0.001262\n",
            "Sadness_lag4                        0.001218\n",
            "Sadness_lag1_lag3                   0.001218\n",
            "Disgust_lag3                        0.001042\n",
            "Disgust_lag1_lag2                   0.001042\n",
            "Negative_lag1_lag2_lag3             0.001031\n",
            "Negative_lag2_lag4                  0.001031\n",
            "Trust_lag1_lag3_lag4                0.001022\n",
            "Fear_lag2_lag3_lag4                 0.000990\n",
            "Disgust                             0.000979\n",
            "Anticipation_lag1_lag3              0.000950\n",
            "Anticipation_lag4                   0.000950\n",
            "Sadness_lag2_lag4                   0.000788\n",
            "Sadness_lag1_lag2_lag3              0.000788\n",
            "Anticipation_lag1_lag2_lag3_lag4    0.000779\n",
            "Positive_lag2_lag4                  0.000721\n",
            "Positive_lag1_lag2_lag3             0.000721\n",
            "Positive                            0.000701\n",
            "Sadness_lag1_lag2_lag3_lag4         0.000698\n",
            "Positive_lag1_lag3_lag4             0.000608\n",
            "Anger_lag1_lag2_lag3                0.000557\n",
            "Anger_lag2_lag4                     0.000557\n",
            "Surprise_lag1_lag2                  0.000456\n",
            "Surprise_lag3                       0.000456\n",
            "Trust_lag1_lag2_lag3_lag4           0.000420\n",
            "Sadness_lag1_lag2_lag4              0.000413\n",
            "Sadness_lag3_lag4                   0.000413\n",
            "Negative_lag1                       0.000384\n",
            "Trust_lag1                          0.000359\n",
            "Joy_lag4                            0.000350\n",
            "Joy_lag1_lag3                       0.000350\n",
            "Positive_lag2                       0.000348\n",
            "Surprise_lag1                       0.000307\n",
            "Anger                               0.000269\n",
            "Negative_lag3_lag4                  0.000268\n",
            "Negative_lag1_lag2_lag4             0.000268\n",
            "Fear_lag1_lag2_lag3_lag4            0.000262\n",
            "Anticipation                        0.000239\n",
            "Positive_lag3_lag4                  0.000210\n",
            "Positive_lag1_lag2_lag4             0.000210\n",
            "Surprise_lag1_lag3_lag4             0.000202\n",
            "Negative_lag1_lag3_lag4             0.000188\n",
            "Anticipation_lag1_lag2              0.000105\n",
            "Anticipation_lag3                   0.000105\n",
            "Positive_lag2_lag3                  0.000067\n",
            "Positive_lag1_lag4                  0.000067\n",
            "Negative_lag2                       0.000047\n",
            "Joy_lag3_lag4                       0.000025\n",
            "Joy_lag1_lag2_lag4                  0.000025\n",
            "Joy_lag2_lag3                      -0.000024\n",
            "Joy_lag1_lag4                      -0.000024\n",
            "Positive_lag4                      -0.000025\n",
            "Positive_lag1_lag3                 -0.000025\n",
            "Surprise_lag1_lag2_lag3_lag4       -0.000029\n",
            "Anger_lag3_lag4                    -0.000042\n",
            "Anger_lag1_lag2_lag4               -0.000042\n",
            "Fear_lag2_lag4                     -0.000069\n",
            "Fear_lag1_lag2_lag3                -0.000069\n",
            "Sadness_lag1_lag2                  -0.000142\n",
            "Sadness_lag3                       -0.000142\n",
            "Joy_lag2_lag4                      -0.000164\n",
            "Joy_lag1_lag2_lag3                 -0.000164\n",
            "Trust_lag2                         -0.000229\n",
            "Fear_lag1                          -0.000230\n",
            "Sadness_lag2_lag3                  -0.000238\n",
            "Sadness_lag1_lag4                  -0.000238\n",
            "Anticipation_lag1_lag3_lag4        -0.000254\n",
            "Disgust_lag2                       -0.000295\n",
            "Joy_lag2_lag3_lag4                 -0.000313\n",
            "Fear_lag1_lag2_lag4                -0.000318\n",
            "Fear_lag3_lag4                     -0.000318\n",
            "Anticipation_lag2                  -0.000324\n",
            "Negative_lag2_lag3_lag4            -0.000351\n",
            "Positive_lag3                      -0.000416\n",
            "Positive_lag1_lag2                 -0.000416\n",
            "Negative_lag3                      -0.000435\n",
            "Negative_lag1_lag2                 -0.000435\n",
            "Surprise_lag1_lag3                 -0.000460\n",
            "Surprise_lag4                      -0.000460\n",
            "Fear_lag1_lag2                     -0.000461\n",
            "Fear_lag3                          -0.000461\n",
            "Trust_lag3_lag4                    -0.000516\n",
            "Trust_lag1_lag2_lag4               -0.000516\n",
            "Disgust_lag1_lag2_lag3_lag4        -0.000555\n",
            "Surprise_lag2_lag4                 -0.000560\n",
            "Surprise_lag1_lag2_lag3            -0.000560\n",
            "Negative_lag1_lag4                 -0.000579\n",
            "Negative_lag2_lag3                 -0.000579\n",
            "Sadness                            -0.000587\n",
            "Fear_lag1_lag4                     -0.000715\n",
            "Fear_lag2_lag3                     -0.000715\n",
            "Trust_lag2_lag4                    -0.000732\n",
            "Trust_lag1_lag2_lag3               -0.000732\n",
            "Surprise_lag2_lag3_lag4            -0.000843\n",
            "Joy_lag1_lag2                      -0.000920\n",
            "Joy_lag3                           -0.000920\n",
            "Sadness_lag1_lag3_lag4             -0.000967\n",
            "Surprise_lag3_lag4                 -0.000979\n",
            "Surprise_lag1_lag2_lag4            -0.000979\n",
            "Anger_lag1                         -0.001007\n",
            "Anger_lag1_lag3_lag4               -0.001059\n",
            "Anticipation_lag1                  -0.001066\n",
            "Anticipation_lag2_lag3_lag4        -0.001126\n",
            "Joy_lag1_lag3_lag4                 -0.001131\n",
            "Sadness_lag1                       -0.001135\n",
            "Fear_lag1_lag3                     -0.001152\n",
            "Fear_lag4                          -0.001152\n",
            "Surprise_lag2_lag3                 -0.001213\n",
            "Surprise_lag1_lag4                 -0.001213\n",
            "Surprise_lag2                      -0.001248\n",
            "Anger_lag1_lag2_lag3_lag4          -0.001382\n",
            "Disgust_lag1                       -0.001389\n",
            "Joy_lag2                           -0.001415\n",
            "Joy_lag1_lag2_lag3_lag4            -0.001449\n",
            "Anger_lag1_lag2                    -0.001489\n",
            "Anger_lag3                         -0.001489\n",
            "Trust_lag1_lag3                    -0.001661\n",
            "Trust_lag4                         -0.001661\n",
            "Anticipation_lag3_lag4             -0.001676\n",
            "Anticipation_lag1_lag2_lag4        -0.001676\n",
            "Disgust_lag1_lag3_lag4             -0.001773\n",
            "Anticipation_lag1_lag4             -0.001873\n",
            "Anticipation_lag2_lag3             -0.001873\n",
            "Trust_lag2_lag3_lag4               -0.001878\n",
            "Anger_lag1_lag4                    -0.001880\n",
            "Anger_lag2_lag3                    -0.001880\n",
            "Fear                               -0.001995\n",
            "Anticipation_lag1_lag2_lag3        -0.002078\n",
            "Anticipation_lag2_lag4             -0.002078\n",
            "Trust_lag3                         -0.002451\n",
            "Trust_lag1_lag2                    -0.002451\n",
            "Joy_lag1                           -0.002617\n",
            "Disgust_lag2_lag3                  -0.002651\n",
            "Disgust_lag1_lag4                  -0.002651\n",
            "Positive_lag2_lag3_lag4            -0.002711\n",
            "Positive_lag1                      -0.003406\n",
            "Negative                           -0.003688\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Pandas options to display all rows and columns\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew3Ca8XxhgQy",
        "outputId": "b70aefe2-1c42-4314-fea6-bd82447a0d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Importance:\n",
            "Disgust_lag1_lag3              0.007259\n",
            "Anger_lag1_lag3                0.006770\n",
            "Disgust_lag1_lag2_lag3         0.006576\n",
            "Joy                            0.005530\n",
            "Fear_lag2                      0.004878\n",
            "Positive_lag1_lag2_lag3        0.003688\n",
            "Surprise                       0.003144\n",
            "Trust_lag2                     0.002997\n",
            "Sadness_lag1_lag3              0.002992\n",
            "Positive_lag1_lag3             0.002864\n",
            "Trust                          0.002749\n",
            "Anger_lag2                     0.002692\n",
            "Anger_lag1_lag2_lag3           0.002613\n",
            "Trust_lag1                     0.002539\n",
            "Negative_lag1                  0.002499\n",
            "Trust_lag2_lag3                0.002485\n",
            "Surprise_lag1_lag2             0.001882\n",
            "Surprise_lag3                  0.001882\n",
            "Anticipation_lag2              0.001796\n",
            "Surprise_lag1                  0.001588\n",
            "Fear_lag1                      0.001366\n",
            "Disgust                        0.001342\n",
            "Joy_lag2_lag3                  0.001249\n",
            "Sadness_lag1_lag2_lag3         0.001181\n",
            "Disgust_lag3                   0.001052\n",
            "Disgust_lag1_lag2              0.001052\n",
            "Sadness_lag2_lag3              0.000568\n",
            "Joy_lag1_lag2_lag3             0.000494\n",
            "Positive_lag2                  0.000452\n",
            "Joy_lag1_lag3                  0.000378\n",
            "Negative_lag1_lag2_lag3        0.000289\n",
            "Positive                       0.000261\n",
            "Surprise_lag1_lag3             0.000191\n",
            "Anger                          0.000174\n",
            "Anticipation_lag3              0.000166\n",
            "Anticipation_lag1_lag2         0.000166\n",
            "Positive_lag3                 -0.000186\n",
            "Positive_lag1_lag2            -0.000186\n",
            "Fear_lag1_lag2                -0.000202\n",
            "Fear_lag3                     -0.000202\n",
            "Negative_lag1_lag3            -0.000272\n",
            "Sadness_lag2                  -0.000319\n",
            "Sadness_lag3                  -0.000375\n",
            "Sadness_lag1_lag2             -0.000375\n",
            "Surprise_lag2_lag3            -0.000431\n",
            "Anticipation_lag1_lag3        -0.000630\n",
            "Sadness                       -0.000720\n",
            "Anticipation                  -0.000849\n",
            "Trust_lag1_lag2_lag3          -0.000928\n",
            "Surprise_lag2                 -0.000978\n",
            "Positive_lag2_lag3            -0.000978\n",
            "Sadness_lag1                  -0.001129\n",
            "Surprise_lag1_lag2_lag3       -0.001276\n",
            "Anger_lag1                    -0.001471\n",
            "Disgust_lag2                  -0.001490\n",
            "Negative_lag2                 -0.001548\n",
            "Anger_lag1_lag2               -0.001593\n",
            "Anger_lag3                    -0.001593\n",
            "Disgust_lag1                  -0.001652\n",
            "Joy_lag1_lag2                 -0.001747\n",
            "Joy_lag3                      -0.001747\n",
            "Trust_lag3                    -0.002083\n",
            "Trust_lag1_lag2               -0.002083\n",
            "Fear_lag2_lag3                -0.002479\n",
            "Trust_lag1_lag3               -0.002701\n",
            "Negative_lag2_lag3            -0.002705\n",
            "Negative_lag1_lag2            -0.002975\n",
            "Negative_lag3                 -0.002975\n",
            "Anticipation_lag1             -0.003004\n",
            "Anticipation_lag2_lag3        -0.003089\n",
            "Positive_lag1                 -0.003165\n",
            "Joy_lag2                      -0.003305\n",
            "Joy_lag1                      -0.003346\n",
            "Fear_lag1_lag2_lag3           -0.003692\n",
            "Fear_lag1_lag3                -0.004391\n",
            "Anger_lag2_lag3               -0.004617\n",
            "Fear                          -0.005021\n",
            "Disgust_lag2_lag3             -0.006200\n",
            "Negative                      -0.006392\n",
            "Anticipation_lag1_lag2_lag3   -0.007050\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time Series Regression Evaluation"
      ],
      "metadata": {
        "id": "t4vTxKkR4ulI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n",
        "# Calculate R² Score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R² Score: {r2:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5sWQ3Un4t5E",
        "outputId": "eeff7639-5ade-403f-aac2-89db9aa1e0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.43\n",
            "R² Score: -0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_predictions = [y_train.mean()] * len(y_test)\n",
        "baseline_r2 = r2_score(y_test, baseline_predictions)\n",
        "print(f\"Baseline R²: {baseline_r2:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO6fde-nCDzv",
        "outputId": "f286631d-8f3d-407d-ee29-0d1e2382414f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline R²: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Time Series shows the worst test performance among all 3 models**\n",
        "\n",
        "## Now we want to improve its performance by applying regularization (Ridge, Lasso)\n",
        "\n",
        "\n",
        "\n",
        "*   Ridge Regression\n",
        "    * Penalizes large coefficients to reduce model complexity.\n",
        "    * Suitable for handling multicollinearity without dropping features.\n",
        "*   Lasso Regression\n",
        "    * Shrinks some coefficients to zero, effectively performing feature selection.\n",
        "    * Useful for reducing the number of lagged features when many have minimal impact.\n"
      ],
      "metadata": {
        "id": "LyjxirOe9Qzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Season 5 Hypothetical Data and Prediction Script: Simulate Feature Changes of Ratings\n",
        "\n",
        "* Understand how increasing or decreasing important features (e.g., Anger_lag1_lag3) influences ratings."
      ],
      "metadata": {
        "id": "r5tJiYAp3sJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Original predictions\n",
        "original_predictions = model.predict(X_test)\n",
        "\n",
        "# Simulate changes: Increase Anger_lag1_lag3 by 10%\n",
        "X_test_simulated = X_test.copy()\n",
        "X_test_simulated['Anger_lag1_lag3'] *= 1.1\n",
        "\n",
        "# Predict with modified features\n",
        "simulated_predictions = model.predict(X_test_simulated)\n",
        "\n",
        "# Compare predictions\n",
        "change_in_ratings = simulated_predictions - original_predictions\n",
        "results = pd.DataFrame({\n",
        "    'Original Ratings': original_predictions,\n",
        "    'Modified Ratings': simulated_predictions,\n",
        "    'Change in Ratings': change_in_ratings\n",
        "})\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDxCcZ-F6ySu",
        "outputId": "498ca2cd-4fd4-49a8-ae66-57abce4bd137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Original Ratings  Modified Ratings  Change in Ratings\n",
            "0          6.880249          6.887019           0.006770\n",
            "1          6.720912          6.742576           0.021665\n",
            "2          6.486834          6.517976           0.031143\n",
            "3          6.865740          6.877926           0.012186\n",
            "4          6.528356          6.547990           0.019634\n",
            "5          6.038126          6.055729           0.017602\n",
            "6          6.469302          6.486905           0.017602\n",
            "7          6.441398          6.454938           0.013540\n",
            "8          6.933783          6.950709           0.016925\n",
            "9          7.129827          7.147429           0.017602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see for example when we increase anger_lag1_lge3 by 10%, predicted ratings are predicted to be higher than before.\n",
        "We assume this might be due to increasing audience engagement due to more intense conflicts between characters in the show."
      ],
      "metadata": {
        "id": "GSOOzm934VoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: LSTM"
      ],
      "metadata": {
        "id": "IcVGG6vy4bUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('EIPData.csv')\n",
        "\n",
        "# Select features and target\n",
        "emotion_features = [\"Positive\", \"Trust\", \"Joy\", \"Anticipation\", \"Negative\",\n",
        "                    \"Surprise\", \"Sadness\", \"Fear\", \"Anger\", \"Disgust\"]\n",
        "X = data[emotion_features].values\n",
        "y = data['IMDB ratings (out of 10)'].values  # Target variable\n",
        "\n",
        "# Normalize the data\n",
        "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "# Create sequences for LSTM\n",
        "def create_sequences(X, y, time_steps=3):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_seq.append(X[i:i + time_steps])\n",
        "        y_seq.append(y[i + time_steps])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "time_steps = 3\n",
        "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
        "\n",
        "# Split into training and testing sets\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = y_seq[:split], y_seq[split:]\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, activation='relu', return_sequences=True, input_shape=(time_steps, X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_test_rescaled = scaler_y.inverse_transform(y_test)\n",
        "y_pred_rescaled = scaler_y.inverse_transform(y_pred)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test_rescaled, y_pred_rescaled))\n",
        "print(f\"Test RMSE: {rmse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gs6a_pgz4a1K",
        "outputId": "755ca8c4-0b60-4ac0-cc99-7bb977ee6d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m12,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,451\u001b[0m (126.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,451</span> (126.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,451\u001b[0m (126.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,451</span> (126.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 242ms/step - loss: 0.1879 - val_loss: 0.0947\n",
            "Epoch 2/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2112 - val_loss: 0.0798\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1690 - val_loss: 0.0654\n",
            "Epoch 4/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.1377 - val_loss: 0.0519\n",
            "Epoch 5/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1311 - val_loss: 0.0403\n",
            "Epoch 6/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1097 - val_loss: 0.0334\n",
            "Epoch 7/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0804 - val_loss: 0.0355\n",
            "Epoch 8/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0636 - val_loss: 0.0490\n",
            "Epoch 9/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0643 - val_loss: 0.0696\n",
            "Epoch 10/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0761 - val_loss: 0.0825\n",
            "Epoch 11/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0940 - val_loss: 0.0689\n",
            "Epoch 12/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0613 - val_loss: 0.0574\n",
            "Epoch 13/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0730 - val_loss: 0.0471\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0718 - val_loss: 0.0399\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0765 - val_loss: 0.0363\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0633 - val_loss: 0.0339\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0668 - val_loss: 0.0329\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0698 - val_loss: 0.0330\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0652 - val_loss: 0.0332\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0700 - val_loss: 0.0342\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0723 - val_loss: 0.0345\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0527 - val_loss: 0.0350\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0625 - val_loss: 0.0351\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0589 - val_loss: 0.0344\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0491 - val_loss: 0.0337\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0576 - val_loss: 0.0329\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0600 - val_loss: 0.0333\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0527 - val_loss: 0.0349\n",
            "Epoch 29/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0597 - val_loss: 0.0353\n",
            "Epoch 30/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0745 - val_loss: 0.0348\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0484 - val_loss: 0.0329\n",
            "Epoch 32/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0599 - val_loss: 0.0329\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0375 - val_loss: 0.0303\n",
            "Epoch 34/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0480 - val_loss: 0.0292\n",
            "Epoch 35/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0534 - val_loss: 0.0296\n",
            "Epoch 36/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0433 - val_loss: 0.0289\n",
            "Epoch 37/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0481 - val_loss: 0.0283\n",
            "Epoch 38/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0463 - val_loss: 0.0300\n",
            "Epoch 39/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0373 - val_loss: 0.0296\n",
            "Epoch 40/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0495 - val_loss: 0.0305\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0473 - val_loss: 0.0276\n",
            "Epoch 42/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0348 - val_loss: 0.0287\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0358 - val_loss: 0.0320\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0370 - val_loss: 0.0313\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0531 - val_loss: 0.0320\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0421 - val_loss: 0.0311\n",
            "Epoch 47/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0480 - val_loss: 0.0333\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0359 - val_loss: 0.0324\n",
            "Epoch 49/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0399 - val_loss: 0.0336\n",
            "Epoch 50/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0353 - val_loss: 0.0298\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step\n",
            "Test RMSE: 0.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model 3: Random Forests"
      ],
      "metadata": {
        "id": "dW3srtR0duxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'EIPData.csv'  # Replace with your file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Select features and target\n",
        "emotion_features = [\"Positive\", \"Trust\", \"Joy\", \"Anticipation\", \"Negative\",\n",
        "                    \"Surprise\", \"Sadness\", \"Fear\", \"Anger\", \"Disgust\"]\n",
        "X = data[emotion_features]\n",
        "y = data['IMDB ratings (out of 10)']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=False)\n",
        "\n",
        "# Train the Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Feature Importance\n",
        "feature_importance = pd.Series(rf_model.feature_importances_, index=emotion_features).sort_values(ascending=False)\n",
        "\n",
        "# Output results\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R^2 Score: {r2:.2f}\")\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "id": "vvi9mUdz3rIs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "baaea9ba-46d5-4295-fc06-9fbac192ea5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'EIPData.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5d11b07397a3>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EIPData.csv'\u001b[0m  \u001b[0;31m# Replace with your file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Select features and target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'EIPData.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the trained model from previous steps is available as 'model'\n",
        "\n",
        "# Generate synthetic test data for Season 5\n",
        "season_5_test_data = {\n",
        "    \"Positive\": np.random.randint(50, 100, size=10),\n",
        "    \"Trust\": np.random.randint(30, 80, size=10),\n",
        "    \"Joy\": np.random.randint(40, 90, size=10),\n",
        "    \"Anticipation\": np.random.randint(20, 70, size=10),\n",
        "    \"Negative\": np.random.randint(10, 50, size=10),\n",
        "    \"Surprise\": np.random.randint(20, 60, size=10),\n",
        "    \"Sadness\": np.random.randint(10, 40, size=10),\n",
        "    \"Fear\": np.random.randint(10, 30, size=10),\n",
        "    \"Anger\": np.random.randint(5, 25, size=10),\n",
        "    \"Disgust\": np.random.randint(5, 15, size=10),\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "season_5_test_df = pd.DataFrame(season_5_test_data)\n",
        "\n",
        "# Predict ratings for Season 5\n",
        "season_5_test_df['Predicted_Rating'] = rf_model.predict(season_5_test_df)\n",
        "\n",
        "# Display the test data with predicted ratings\n",
        "print(season_5_test_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "296x2S4PffdV",
        "outputId": "56139961-123c-47b0-9ba7-35eafcff7db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Positive  Trust  Joy  Anticipation  Negative  Surprise  Sadness  Fear  \\\n",
            "0        66     40   76            49        46        48       31    11   \n",
            "1        69     49   70            28        42        58       11    18   \n",
            "2        58     34   46            47        48        23       23    13   \n",
            "3        82     46   71            68        25        46       23    13   \n",
            "4        64     71   64            60        40        21       25    29   \n",
            "5        88     65   81            23        26        40       33    14   \n",
            "6        93     54   86            44        12        42       10    27   \n",
            "7        59     63   54            61        23        39       27    17   \n",
            "8        90     66   72            24        46        21       37    22   \n",
            "9        84     47   85            35        33        33       30    11   \n",
            "\n",
            "   Anger  Disgust  Predicted_Rating  \n",
            "0     13       12          7.158233  \n",
            "1     10       10          7.058017  \n",
            "2     13       14          7.105500  \n",
            "3     16       14          7.139167  \n",
            "4     13       10          7.009261  \n",
            "5      7        8          7.158250  \n",
            "6      5       14          6.992000  \n",
            "7     17        8          7.082767  \n",
            "8     21       14          6.924825  \n",
            "9     17       12          7.163150  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Train-test split (assuming X and y are preprocessed)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=False)\n",
        "\n",
        "# Ridge Regression\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train, y_train)\n",
        "ridge_pred = ridge.predict(X_test)\n",
        "ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge_pred))\n",
        "ridge_r2 = r2_score(y_test, ridge_pred)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
        "rf_r2 = r2_score(y_test, rf_pred)\n",
        "\n",
        "# Gradient Boosting (XGBoost)\n",
        "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
        "xgb_r2 = r2_score(y_test, xgb_pred)\n",
        "\n",
        "# LSTM (requires reshaping X for sequential data)\n",
        "X_train_seq = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_seq = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "lstm_model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(X_train_seq.shape[1], 1)),\n",
        "    LSTM(50),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm_model.compile(optimizer='adam', loss='mse')\n",
        "lstm_model.fit(X_train_seq, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "lstm_pred = lstm_model.predict(X_test_seq).flatten()\n",
        "lstm_rmse = np.sqrt(mean_squared_error(y_test, lstm_pred))\n",
        "lstm_r2 = r2_score(y_test, lstm_pred)\n",
        "\n",
        "# Compare Results\n",
        "print(f\"Ridge RMSE: {ridge_rmse:.2f}, R^2: {ridge_r2:.2f}\")\n",
        "print(f\"Random Forest RMSE: {rf_rmse:.2f}, R^2: {rf_r2:.2f}\")\n",
        "print(f\"XGBoost RMSE: {xgb_rmse:.2f}, R^2: {xgb_r2:.2f}\")\n",
        "print(f\"LSTM RMSE: {lstm_rmse:.2f}, R^2: {lstm_r2:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSWGrIxdFyTy",
        "outputId": "59473e06-4336-4dd1-b6ba-d7a612d7a943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step\n",
            "Ridge RMSE: 0.44, R^2: -0.69\n",
            "Random Forest RMSE: 0.33, R^2: 0.06\n",
            "XGBoost RMSE: 0.36, R^2: -0.11\n",
            "LSTM RMSE: 0.57, R^2: -1.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will select Random Forest in this case as it has the lowest RMSE and highest R^2"
      ],
      "metadata": {
        "id": "FleyYtdkGP9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Modeling"
      ],
      "metadata": {
        "id": "CLa-nb_3HaU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate model results for Random Forests, for example, show the most important features affecting ratings (can you make the output look better)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'EIPData.csv'  # Replace with your file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Select features and target\n",
        "emotion_features = [\"Positive\", \"Trust\", \"Joy\", \"Anticipation\", \"Negative\",\n",
        "                    \"Surprise\", \"Sadness\", \"Fear\", \"Anger\", \"Disgust\"]\n",
        "X = data[emotion_features]\n",
        "y = data['IMDB ratings (out of 10)']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=False)\n",
        "\n",
        "# Train the Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Feature Importance\n",
        "feature_importance = pd.Series(rf_model.feature_importances_, index=emotion_features).sort_values(ascending=False)\n",
        "\n",
        "# Output results\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R^2 Score: {r2:.2f}\")\n",
        "\n",
        "print(\"\\nFeature Importance (Random Forest):\")\n",
        "print(feature_importance.to_string()) # Use to_string for better formatting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a-lxEwUHZ8l",
        "outputId": "e7f3ac48-afe2-4ab4-f75e-98eafe0247a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.35\n",
            "R^2 Score: -0.06\n",
            "\n",
            "Feature Importance (Random Forest):\n",
            "Positive        0.210496\n",
            "Fear            0.136893\n",
            "Disgust         0.129797\n",
            "Surprise        0.104712\n",
            "Negative        0.098871\n",
            "Trust           0.086823\n",
            "Anger           0.084126\n",
            "Joy             0.067909\n",
            "Anticipation    0.049358\n",
            "Sadness         0.031015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: can you create a pretty visualization to show the output result of the feature importance (random forest), can you make more important feature more purple and less important feature another color\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'feature_importance' is already calculated from your Random Forest model\n",
        "# Example feature_importance (replace with your actual data):\n",
        "# feature_importance = pd.Series({'Joy': 0.3, 'Anger': 0.2, 'Sadness': 0.15, 'Trust': 0.12, 'Fear': 0.1, 'Positive': 0.08, 'Anticipation': 0.05})\n",
        "\n",
        "# Normalize the feature importances for color mapping\n",
        "normalized_importance = feature_importance / feature_importance.max()\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=feature_importance.index, y=feature_importance.values, palette=\"viridis\") # Use viridis palette\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Feature Importance\")\n",
        "plt.title(\"Feature Importance (Random Forest)\")\n",
        "\n",
        "# Add color mapping\n",
        "for i, v in enumerate(feature_importance):\n",
        "  color = plt.cm.Purples(normalized_importance[i]) # Purple for higher importance\n",
        "  plt.text(i, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', color=color) # Show the value and map to color\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "G8ZkZBzJGDuC",
        "outputId": "45f944ef-5b3b-46f2-a3e1-82fb7c31a916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-add063a5c500>:15: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=feature_importance.index, y=feature_importance.values, palette=\"viridis\") # Use viridis palette\n",
            "<ipython-input-38-add063a5c500>:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  color = plt.cm.Purples(normalized_importance[i]) # Purple for higher importance\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACz70lEQVR4nOzdd3wUdf7H8fduym56IY0AEpr0XiJFQcgZwMZPRODwgKhweqInOT1FpVqCDVFp53l2UcR6eh6KEUSlKUWQJiA9lUA6abvz+yOXhSUJEMyyJLyej8c+zH7nO9/5zGSJeWdmvmMyDMMQAAAAAACodWZ3FwAAAAAAQH1F6AYAAAAAwEUI3QAAAAAAuAihGwAAAAAAFyF0AwAAAADgIoRuAAAAAABchNANAAAAAICLELoBAAAAAHARQjcAAAAAAC5C6AYAAG516NAhWa1W/fDDD+4u5axiYmI0fvx4d5dRL40aNUq33HKLu8sAgFpH6AaAeuz111+XyWSq8vXQQw+5ZJurV6/WjBkzlJ2d7ZLxf4+K4/HTTz+5u5TztmDBAr3++uvuLqNWzZo1S7Gxserbt6+jbfz48U6fV4vFossvv1zTpk1TUVGRG6u9uJx+nE59LVu2zN3lVZKSkqIZM2Zo8+bNlZY9+OCD+vDDD/Xzzz9f+MIAwIU83V0AAMD1Zs2apWbNmjm1dejQwSXbWr16tWbOnKnx48crODjYJdu4lC1YsEBhYWH15mxrZmam3njjDb3xxhuVllksFr3yyiuSpJycHH366ad67LHHtHfvXr3zzjsXutSL1qnH6VSdO3d2QzVnlpKSopkzZyomJkZdunRxWta1a1f16NFDzz33nN588033FAgALkDoBoBLwJAhQ9SjRw93l/G7FBQUyM/Pz91luE1hYaF8fX3dXUate/vtt+Xp6anrr7++0jJPT0/deuutjvd/+ctf1KdPH7377ruaM2eOIiMjL2SpF63Tj1NtutCfu1tuuUXTp0/XggUL5O/vf8G2CwCuxOXlAAD997//1ZVXXik/Pz8FBATo2muv1bZt25z6bNmyRePHj1fz5s1ltVoVFRWl2267TVlZWY4+M2bM0AMPPCBJatasmeMy1/3792v//v0ymUxVXhptMpk0Y8YMp3FMJpO2b9+uP/7xjwoJCVG/fv0cy99++211795dPj4+Cg0N1ahRo3To0KHz2vfx48fL399fBw8e1HXXXSd/f381atRI8+fPlyRt3bpVAwcOlJ+fn5o2barFixc7rV9xyfqqVav05z//WQ0aNFBgYKDGjh2r48ePV9reggUL1L59e1ksFkVHR+vuu++udCn+gAED1KFDB23YsEFXXXWVfH199fDDDysmJkbbtm3Tt99+6zi2AwYMkCQdO3ZM999/vzp27Ch/f38FBgZqyJAhlS7VXblypUwmk95//3098cQTaty4saxWqwYNGqQ9e/ZUqnfdunUaOnSoQkJC5Ofnp06dOumFF15w6rNz507dfPPNCg0NldVqVY8ePfTvf//7nI7/J598otjY2HMKWCaTSf369ZNhGPrtt98c7QcOHNBf/vIXtW7dWj4+PmrQoIFGjBih/fv3O61f8b364YcflJiYqPDwcPn5+en//u//lJmZ6dTXMAw9/vjjaty4sXx9fXX11VdX+jdR4bffftOIESMUGhoqX19fXXHFFfrPf/7j1OfU4z5z5kw1atRIAQEBuvnmm5WTk6Pi4mLdd999ioiIkL+/vxISElRcXHxOx/Bc/J7PnSQVFxdr+vTpatmypSwWi5o0aaK///3vlWpcvny5+vXrp+DgYPn7+6t169aOMVauXKmePXtKkhISEhyf4VN/JvzhD39QQUGBli9fXmv7DgDuxpluALgE5OTk6OjRo05tYWFhkqS33npL48aNU3x8vJ566ikVFhZq4cKF6tevnzZt2qSYmBhJ5b9M//bbb0pISFBUVJS2bduml19+Wdu2bdPatWtlMpl000036ddff9W7776r559/3rGN8PDwSqHmXIwYMUKtWrXSk08+KcMwJElPPPGEpk6dqltuuUV33HGHMjMz9dJLL+mqq67Spk2bzuuSdpvNpiFDhuiqq67S008/rXfeeUeTJk2Sn5+fHnnkEY0ZM0Y33XSTFi1apLFjx6p3796VLtefNGmSgoODNWPGDO3atUsLFy7UgQMHHGFLKv9jwsyZMxUXF6e77rrL0e/HH3/UDz/8IC8vL8d4WVlZGjJkiEaNGqVbb71VkZGRGjBggO655x75+/vrkUcekSTH2d7ffvtNn3zyiUaMGKFmzZopPT1d//jHP9S/f39t375d0dHRTvXOnj1bZrNZ999/v3JycvT0009rzJgxWrdunaPP8uXLdd1116lhw4b661//qqioKO3YsUOff/65/vrXv0qStm3bpr59+6pRo0Z66KGH5Ofnp/fff1/Dhg3Thx9+qP/7v/+r9riXlpbqxx9/1F133XXO36uKIB0SEuJo+/HHH7V69WqNGjVKjRs31v79+7Vw4UINGDBA27dvr3Sm9p577lFISIimT5+u/fv3a+7cuZo0aZKWLFni6DNt2jQ9/vjjGjp0qIYOHaqNGzfqmmuuUUlJidNY6enp6tOnjwoLC3XvvfeqQYMGeuONN3TDDTfogw8+qLT/SUlJ8vHx0UMPPaQ9e/bopZdekpeXl8xms44fP64ZM2Zo7dq1ev3119WsWTNNmzbtnI7L6f++vby8FBQUJOn3f+7sdrtuuOEGff/995o4caLatm2rrVu36vnnn9evv/6qTz75RFL5Z+G6665Tp06dNGvWLFksFu3Zs8cxQV7btm01a9YsTZs2TRMnTtSVV14pSerTp49j++3atZOPj49++OGHM352AKBOMQAA9dZrr71mSKryZRiGkZeXZwQHBxsTJkxwWi8tLc0ICgpyai8sLKw0/rvvvmtIMlatWuVoe+aZZwxJxr59+5z67tu3z5BkvPbaa5XGkWRMnz7d8X769OmGJGP06NFO/fbv3294eHgYTzzxhFP71q1bDU9Pz0rt1R2PH3/80dE2btw4Q5Lx5JNPOtqOHz9u+Pj4GCaTyXjvvfcc7Tt37qxUa8WY3bt3N0pKShztTz/9tCHJ+PTTTw3DMIyMjAzD29vbuOaaawybzeboN2/ePEOS8eqrrzra+vfvb0gyFi1aVGkf2rdvb/Tv379Se1FRkdO4hlF+zC0WizFr1ixH24oVKwxJRtu2bY3i4mJH+wsvvGBIMrZu3WoYhmGUlZUZzZo1M5o2bWocP37caVy73e74etCgQUbHjh2NoqIip+V9+vQxWrVqVanOU+3Zs8eQZLz00kuVlo0bN87w8/MzMjMzjczMTGPPnj3Gs88+a5hMJqNDhw5ONVT12VyzZo0hyXjzzTcdbRXfq7i4OKf1J0+ebHh4eBjZ2dmGYZz8Xl177bVO/R5++GFDkjFu3DhH23333WdIMr777jtHW15entGsWTMjJibG8T2pOO4dOnRw+pyMHj3aMJlMxpAhQ5zq7927t9G0adMzHr+K41TVv++Kz0htfO7eeustw2w2O+2jYRjGokWLDEnGDz/8YBiGYTz//POGJCMzM7Paen/88cdqfw5UuPzyyysdDwCoy7i8HAAuAfPnz9fy5cudXlL5mczs7GyNHj1aR48edbw8PDwUGxurFStWOMbw8fFxfF1UVKSjR4/qiiuukCRt3LjRJXXfeeedTu8/+ugj2e123XLLLU71RkVFqVWrVk711tQdd9zh+Do4OFitW7eWn5+f0yOMWrdureDgYKdLmytMnDjR6YzhXXfdJU9PT33xxReSpK+//lolJSW67777ZDaf/N/vhAkTFBgYWOlyZIvFooSEhHOu32KxOMa12WzKyspyXN5b1fcnISFB3t7ejvcVZx0r9m3Tpk3at2+f7rvvvkpXD1ScuT927Ji++eYb3XLLLcrLy3N8P7KyshQfH6/du3fryJEj1dZccWvCqWetT1VQUKDw8HCFh4erZcuWuv/++9W3b199+umnjhok589maWmpsrKy1LJlSwUHB1e57xMnTnRa/8orr5TNZtOBAwcknfxe3XPPPU797rvvvkpjffHFF+rVq5fT7Q/+/v6aOHGi9u/fr+3btzv1Hzt2rNPnJDY2VoZh6LbbbnPqFxsbq0OHDqmsrKzKY3Mqq9Va6d/3c88957Qvv+dzt3TpUrVt21Zt2rRx+nc3cOBASXL8u6v4nHz66aey2+1nrbs6ISEhlc7cA0BdxuXlAHAJ6NWrV5UTqe3evVuSHL88ny4wMNDx9bFjxzRz5ky99957ysjIcOqXk5NTi9WedPol3Lt375ZhGGrVqlWV/U8NMzVhtVoVHh7u1BYUFKTGjRs7ha6K9qru1T69Jn9/fzVs2NBxOXRFoGvdurVTP29vbzVv3tyxvEKjRo2cQvHZ2O12vfDCC1qwYIH27dsnm83mWNagQYNK/S+77DKn9xXBt2Lf9u7dK+nMs9zv2bNHhmFo6tSpmjp1apV9MjIy1KhRozPWbvzv1oHTWa1WffbZZ5Kkw4cP6+mnn1ZGRoZTyJakEydOKCkpSa+99pqOHDniNF5Vn82z7XvF9+L072l4eHilPxAcOHBAsbGxlbbRtm1bx/JTj+Hp2664BLxJkyaV2u12u3Jycqr8/p3Kw8NDcXFxVS6rjc/d7t27tWPHjkr/RipU/DwYOXKkXnnlFd1xxx166KGHNGjQIN100026+eabnQL/2RiGUenfHQDUZYRuALiEVZyNeuuttxQVFVVpuafnyf9N3HLLLVq9erUeeOABdenSRf7+/rLb7Ro8ePA5ndWq7pfoU8Ph6U4PV3a7XSaTSf/973/l4eFRqf/5znZc1Vhnaq8uJNam0/f9bJ588klNnTpVt912mx577DGFhobKbDbrvvvuq/L7Uxv7VjHu/fffr/j4+Cr7tGzZstr1K8JkVX/EqKjx1DAZHx+vNm3a6M9//rPTRG333HOPXnvtNd13333q3bu3goKCZDKZNGrUKJft+/m6GD9rp6rqc2e329WxY0fNmTOnynUq/mDg4+OjVatWacWKFfrPf/6jZcuWacmSJRo4cKC++uqravfxdMePH6/2D2sAUBcRuuuQj+ev03vP/KBjaflq2TlS9750rdr2alxl38//+ZO+fHOz9v1S/tfny7tHa8KTcU79V320Xf9e9KN+3ZCi3GMn9M9Nd6lVl4ZO4xQXlWrh377UN+9tVUmxTb3iW+q+BdcpNJLHeAD1QYsWLSRJERER1Z4pk8p/CU5OTtbMmTOdJnaqOFN+qurCdcUZwtNnTD79TNvZ6jUMQ82aNdPll19+zutdCLt379bVV1/teJ+fn6/U1FQNHTpUktS0aVNJ0q5du9S8eXNHv5KSEu3bt++Mx/9U1R3fDz74QFdffbX+9a9/ObVnZ2c7JrSriYrPxi+//FJtbRX74eXldc71n+qyyy6Tj4+P9u3bd079GzZsqMmTJ2vmzJlau3at4/aGDz74QOPGjXNcUi2V3wJx+mftXFV8r3bv3u30vcrMzKz0B4KmTZtq165dlcbYuXOn01juUhufuxYtWujnn3/WoEGDznoG2mw2a9CgQRo0aJDmzJmjJ598Uo888ohWrFihuLi4s65fVlamQ4cO6YYbbjiHvQOAuoF7uuuIb5Zs1YLEZRo/fYD+ufFOtegcpQfi39TxjPwq+29euV+DRnfS8ysSNH/NBEU0CdL917ypzCO5jj5FBSXq2O8yTXzqmmq3O3/yMq3+bJdmLB2pF769TUdTcjXtpndrff8AuEd8fLwCAwP15JNPqrS0tNLyihnHK85QnX7Wbe7cuZXWqXiW9umBJzAwUGFhYVq1apVT+4IFC8653ptuukkeHh6aOXNmpVoMw3B6fNmF9vLLLzsdw4ULF6qsrExDhgyRJMXFxcnb21svvviiU+3/+te/lJOTo2uvvfactuPn51dlmPTw8Kh0TJYuXXrGe6rPpFu3bmrWrJnmzp1baXsV24mIiNCAAQP0j3/8Q6mpqZXGONuM9V5eXurRo4d++umnc67rnnvuka+vr2bPnu1oq2rfX3rppTNeRXEmcXFx8vLy0ksvveQ0blWf96FDh2r9+vVas2aNo62goEAvv/yyYmJi1K5du/OqobbUxufulltu0ZEjR/TPf/6z0rITJ06ooKBAUvktKKfr0qWLJDkeLVbdz4cK27dvV1FRkdOM5gBQ13Gmu45YOme1rp3QXUMSukmSEhddr7X/+VVfvLpRYx66qlL/R9+52en9A6/cqFUfbtfG5N8UP7aLJOmaP5X/N3V/1Zf15ecU6Yt/bdSji29Wt4Hlfx1/8LX/07i2L2nb2kNqf0WTKtcDUHcEBgZq4cKF+tOf/qRu3bpp1KhRCg8P18GDB/Wf//xHffv21bx58xQYGOh4nFZpaakaNWqkr776qsozlN27d5ckPfLIIxo1apS8vLx0/fXXy8/PT3fccYdmz56tO+64Qz169NCqVav066+/nnO9LVq00OOPP64pU6Zo//79GjZsmAICArRv3z59/PHHmjhxou6///5aOz41UVJSokGDBumWW27Rrl27tGDBAvXr189xxi48PFxTpkzRzJkzNXjwYN1www2Ofj179tStt956Ttvp3r27Fi5cqMcff1wtW7ZURESEBg4cqOuuu06zZs1SQkKC+vTpo61bt+qdd95xOrtZE2azWQsXLtT111+vLl26KCEhQQ0bNtTOnTu1bds2ffnll5LKJ+nr16+fOnbsqAkTJqh58+ZKT0/XmjVrdPjw4UrPCT/djTfeqEceeUS5ublOcwhUp0GDBkpISNCCBQu0Y8cOtW3bVtddd53eeustBQUFqV27dlqzZo2+/vrrs94LXZ3w8HDdf//9SkpK0nXXXaehQ4dq06ZN+u9//1vpqoGHHnpI7777roYMGaJ7771XoaGheuONN7Rv3z59+OGHNbqX2RVq43P3pz/9Se+//77uvPNOrVixQn379pXNZtPOnTv1/vvv68svv1SPHj00a9YsrVq1Stdee62aNm2qjIwMLViwQI0bN3ZMNNeiRQsFBwdr0aJFCggIkJ+fn2JjYx3zNyxfvly+vr76wx/+4NLjAgAX1IWdLB3no6S41LjaY7qx6uPtTu1Pjv3QePiGd85pjILcIuMP1pnGD5/trLQsZd8xo7+mGr9uSnFq35C81+ivqUbucedHsdxy2bPG+3N+qOFeAHCHqh6RVZUVK1YY8fHxRlBQkGG1Wo0WLVoY48ePN3766SdHn8OHDxv/93//ZwQHBxtBQUHGiBEjjJSUlEqP0DIMw3jssceMRo0aGWaz2enxYYWFhcbtt99uBAUFGQEBAcYtt9xiZGRkVPvIsOoePfThhx8a/fr1M/z8/Aw/Pz+jTZs2xt13323s2rWrxsej4tFUp+vfv7/Rvn37Su1NmzY1rr322kpjfvvtt8bEiRONkJAQw9/f3xgzZoyRlZVVaf158+YZbdq0Mby8vIzIyEjjrrvuqvRIruq2bRjlj3O79tprjYCAAKdHQxUVFRl/+9vfjIYNGxo+Pj5G3759jTVr1hj9+/d3esRYxaOrli5d6jRudY90+/77740//OEPRkBAgOHn52d06tSp0iO+9u7da4wdO9aIiooyvLy8jEaNGhnXXXed8cEHH1S5D6dKT083PD09jbfeesupvbrvS8X2PDw8HI/uOn78uJGQkGCEhYUZ/v7+Rnx8vLFz506jadOmTo/3qu7fQ8UxWbFihaPNZrMZM2fOdBzPAQMGGL/88kulMSvqufnmm43g4GDDarUavXr1Mj7//PMqt3H6ca+uprP9GziX43Sq3/u5KykpMZ566imjffv2hsViMUJCQozu3bsbM2fONHJycgzDMIzk5GTjxhtvNKKjow1vb28jOjraGD16tPHrr786jfXpp58a7dq1Mzw9PSt95mJjY41bb731rPsDAHWJyTAu8AwdqLGjKbm6udGzmr/6DrXvfXLW00V//1I/f7tfC9f9+axjPP+Xz/Tjl3v02rZJslidZ/dN3X9co5s9X+me7q8Xb9FTCR9refF0p/539vqHul7dTH8+w2XpAHCpeP3115WQkKAff/yxyhnicXa33367fv31V3333XfuLgVutHnzZnXr1k0bN250XJYOAPUB93RfAt6ZvUrfvPeLHvt4dKXADQCAu02fPl0//vijfvjhB3eXAjeaPXu2br75ZgI3gHqHe7rrgKAwX5k9zDqWXuDUfjy9QKFRAWdc971nv9fi2d/rua/HqUWnyo8DOpPQKH+VltiUl31CAcEnHyFyPD1foVHMXg4AqB2XXXaZioqK3F0G3Oy9995zdwkA4BKc6a4DvLw91bp7Q21M/s3RZrfbtSH5N7XrXfUjwyTp3ae/01uPfaunl/1JbXo0qvF2L+8eLU8vD6ftHtx1VOkHc9SuN5OoAQAAAMDZcKa7jhiR2EdJ4z5W6x7RatursT6Yu0ZFBSWO2cyfHPuhwhoFamJS+Wyfi5/6Tq9N+0aPLr5ZUTHBykrLkyT5+HvL198iSco9Vqj0gznKSilfdmjXUUnlZ7gbRAXIP8iqobd304LEZQoM9ZFvoFUv3vMfte/dhJnLAeB/xo8fr/Hjx7u7DAAAcJEidNcRA0d2VHZmoV6b9o2OpeWrZZcoPb3sTwqNLL/MO/1gjkxmk6P/pwt/VGmJTdNvXuI0zrjpA5QwY6Ak6Yd/79JTCR87ls0atbRSn7ufHyyz2aRpw5eotLhMPeNb6r4F17l0XwEAAACgvmD2cgAAAAAAXIQz3efJbrcrJSVFAQEBMplMZ18BAAAAAFBvGIahvLw8RUdHy2yufro0Qvd5SklJUZMm3NcMAAAAAJeyQ4cOqXHj6ie4JnSfp4CA8kd1HTp0SIGBgW6uBgAAAABwIeXm5qpJkyaObFgdQvd5qrikPDAwkNANAAAAAJeos91uzHO6AQAAAABwEUI3AAAAAAAuQugGAAAAAMBFCN0AAAAAALgIoRsAAAAAABchdAMAAAAA4CKEbgAAAAAAXITQDQAAAACAixC6AQAAAABwEUI3AAAAAAAuQugGAAAAAMBFCN0AAAAAALgIoRsAAAAAABchdAMAAAAA4CKEbgAAAAAAXITQDQAAAACAixC6AQAAAABwEUI3AAAAAAAuQugGAAAAAMBFPN1dQH03tONd7i7hovbF1oXuLgEAAAAAXIYz3QAAAAAAuAihGwAAAAAAFyF0AwAAAADgIoRuAAAAAABchNANAAAAAICLELoBAAAAAHARQjcAAAAAAC5C6AYAAAAAwEUI3QAAAAAAuAihGwAAAAAAFyF0AwAAAADgIoRuAAAAAABchNANAAAAAICLELoBAAAAAHARQjcAAAAAAC5C6AYAAAAAwEUuitA9f/58xcTEyGq1KjY2VuvXr6+27z//+U9deeWVCgkJUUhIiOLi4ir1NwxD06ZNU8OGDeXj46O4uDjt3r3bqc+xY8c0ZswYBQYGKjg4WLfffrvy8/Ndsn8AAAAAgEuT20P3kiVLlJiYqOnTp2vjxo3q3Lmz4uPjlZGRUWX/lStXavTo0VqxYoXWrFmjJk2a6JprrtGRI0ccfZ5++mm9+OKLWrRokdatWyc/Pz/Fx8erqKjI0WfMmDHatm2bli9frs8//1yrVq3SxIkTXb6/AAAAAIBLh8kwDMOdBcTGxqpnz56aN2+eJMlut6tJkya655579NBDD511fZvNppCQEM2bN09jx46VYRiKjo7W3/72N91///2SpJycHEVGRur111/XqFGjtGPHDrVr104//vijevToIUlatmyZhg4dqsOHDys6Ovqs283NzVVQUJBycnIUGBhYbb+hHe86l8Nwyfpi60J3lwAAAAAANXaumdCtZ7pLSkq0YcMGxcXFOdrMZrPi4uK0Zs2acxqjsLBQpaWlCg0NlSTt27dPaWlpTmMGBQUpNjbWMeaaNWsUHBzsCNySFBcXJ7PZrHXr1lW5neLiYuXm5jq9AAAAAAA4E7eG7qNHj8pmsykyMtKpPTIyUmlpaec0xoMPPqjo6GhHyK5Y70xjpqWlKSIiwmm5p6enQkNDq91uUlKSgoKCHK8mTZqcU30AAAAAgEuX2+/p/j1mz56t9957Tx9//LGsVqtLtzVlyhTl5OQ4XocOHXLp9gAAAAAAdZ+nOzceFhYmDw8PpaenO7Wnp6crKirqjOs+++yzmj17tr7++mt16tTJ0V6xXnp6uho2bOg0ZpcuXRx9Tp+oraysTMeOHat2uxaLRRaL5Zz3DQAAAAAAt57p9vb2Vvfu3ZWcnOxos9vtSk5OVu/evatd7+mnn9Zjjz2mZcuWOd2XLUnNmjVTVFSU05i5ublat26dY8zevXsrOztbGzZscPT55ptvZLfbFRsbW1u7BwAAAAC4xLn1TLckJSYmaty4cerRo4d69eqluXPnqqCgQAkJCZKksWPHqlGjRkpKSpIkPfXUU5o2bZoWL16smJgYxz3Y/v7+8vf3l8lk0n333afHH39crVq1UrNmzTR16lRFR0dr2LBhkqS2bdtq8ODBmjBhghYtWqTS0lJNmjRJo0aNOqeZywEAAAAAOBduD90jR45UZmampk2bprS0NHXp0kXLli1zTIR28OBBmc0nT8gvXLhQJSUluvnmm53GmT59umbMmCFJ+vvf/66CggJNnDhR2dnZ6tevn5YtW+Z03/c777yjSZMmadCgQTKbzRo+fLhefPFF1+8wAAAAAOCS4fbndNdVPKe7dvCcbgAAAAB1UZ14TjcAAAAAAPUZoRsAAAAAABchdAMAAAAA4CKEbgAAAAAAXITQDQAAAACAixC6AQAAAABwEUI3AAAAAAAuQugGAAAAAMBFCN0AAAAAALgIoRsAAAAAABchdAMAAAAA4CKEbgAAAAAAXITQDQAAAACAixC6AQAAAABwEUI3AAAAAAAuQugGAAAAAMBFCN0AAAAAALgIoRsAAAAAABchdAMAAAAA4CKEbgAAAAAAXITQDQAAAACAixC6AQAAAABwEUI3AAAAAAAuQugGAAAAAMBFCN0AAAAAALgIoRsAAAAAABchdAMAAAAA4CKEbgAAAAAAXITQDQAAAACAixC6AQAAAABwEUI3AAAAAAAuQugGAAAAAMBFCN0AAAAAALgIoRsAAAAAABchdAMAAAAA4CKEbgAAAAAAXITQDQAAAACAixC6AQAAAABwEUI3AAAAAAAu4vbQPX/+fMXExMhqtSo2Nlbr16+vtu+2bds0fPhwxcTEyGQyae7cuZX6VCw7/XX33Xc7+gwYMKDS8jvvvNMVuwcAAAAAuIS5NXQvWbJEiYmJmj59ujZu3KjOnTsrPj5eGRkZVfYvLCxU8+bNNXv2bEVFRVXZ58cff1RqaqrjtXz5cknSiBEjnPpNmDDBqd/TTz9duzsHAAAAALjkuTV0z5kzRxMmTFBCQoLatWunRYsWydfXV6+++mqV/Xv27KlnnnlGo0aNksViqbJPeHi4oqKiHK/PP/9cLVq0UP/+/Z36+fr6OvULDAys9f0DAAAAAFza3Ba6S0pKtGHDBsXFxZ0sxmxWXFyc1qxZU2vbePvtt3XbbbfJZDI5LXvnnXcUFhamDh06aMqUKSosLKyVbQIAAAAAUMHTXRs+evSobDabIiMjndojIyO1c+fOWtnGJ598ouzsbI0fP96p/Y9//KOaNm2q6OhobdmyRQ8++KB27dqljz76qNqxiouLVVxc7Hifm5tbKzUCAAAAAOovt4XuC+Ff//qXhgwZoujoaKf2iRMnOr7u2LGjGjZsqEGDBmnv3r1q0aJFlWMlJSVp5syZLq0XAAAAAFC/uO3y8rCwMHl4eCg9Pd2pPT09vdpJ0mriwIED+vrrr3XHHXectW9sbKwkac+ePdX2mTJlinJychyvQ4cO/e4aAQAAAAD1m9tCt7e3t7p3767k5GRHm91uV3Jysnr37v27x3/ttdcUERGha6+99qx9N2/eLElq2LBhtX0sFosCAwOdXgAAAAAAnIlbLy9PTEzUuHHj1KNHD/Xq1Utz585VQUGBEhISJEljx45Vo0aNlJSUJKl8YrTt27c7vj5y5Ig2b94sf39/tWzZ0jGu3W7Xa6+9pnHjxsnT03kX9+7dq8WLF2vo0KFq0KCBtmzZosmTJ+uqq65Sp06dLtCeAwAAAAAuBW4N3SNHjlRmZqamTZumtLQ0denSRcuWLXNMrnbw4EGZzSdPxqekpKhr166O988++6yeffZZ9e/fXytXrnS0f/311zp48KBuu+22Stv09vbW119/7Qj4TZo00fDhw/Xoo4+6bkcBAAAAAJckk2EYhruLqItyc3MVFBSknJycM15qPrTjXRewqrrni60L3V0CAAAAANTYuWZCt93TDQAAAABAfUfoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFzE090FABebtT/s1/ff7lN+XrGiGgboumHt1fiy4Cr7pqflKfnLX5VyJFfZx09o6A1t1efKZk591q0+oPVrDir7+AlJUkSkv67+Q0td3iZCknT8WKGeS1pZ5fijbu2qDp0b1tq+AQAAALiwCN3AKbZuTtF/P9upG4a3V5PLgrX6u/16/ZX1uu/v/eXvb6nUv7TUptAGvurQuaG++PeOKscMCrbqmqGt1SDMT5KhTT8d0Tuvb9Bf7uunyKgABQX76MGpg5zW+XHdQX3/7W9q1SbcFbsJAAAA4AJx++Xl8+fPV0xMjKxWq2JjY7V+/fpq+27btk3Dhw9XTEyMTCaT5s6dW6nPjBkzZDKZnF5t2rRx6lNUVKS7775bDRo0kL+/v4YPH6709PTa3jXUQT+s2qcesU3UvWcTRUQG6IabOsjLy0Mb1h+usn/jJsEafF1bdeoSLU/Pqv85tWkXqdZtIxQW7qewcH/9YUhreXt76tDBbEmS2WxSQKDF6bXjl3R16NRQFgt/FwMAAADqMreG7iVLligxMVHTp0/Xxo0b1blzZ8XHxysjI6PK/oWFhWrevLlmz56tqKioasdt3769UlNTHa/vv//eafnkyZP12WefaenSpfr222+VkpKim266qVb3DXVPWZldKUdy1aJVA0eb2WxSi1ZhOnTgeK1sw243tGVzikpKbLqsaXCVfY4czlFqSq569GpSK9sEAAAA4D5uPY02Z84cTZgwQQkJCZKkRYsW6T//+Y9effVVPfTQQ5X69+zZUz179pSkKpdX8PT0rDaU5+Tk6F//+pcWL16sgQMHSpJee+01tW3bVmvXrtUVV1zxe3cLdVRhQYnsdqPSZeT+/hYdzcj/XWOnpebq5XlrVFZml7e3h/44rpsiIgOq7Lth/SGFR/jrspiQ37VNAAAAAO7ntjPdJSUl2rBhg+Li4k4WYzYrLi5Oa9as+V1j7969W9HR0WrevLnGjBmjgwcPOpZt2LBBpaWlTttt06aNLrvsst+9XaA6YeH+untyP/35nj7q1fsyfbhkizLS8yr1Ky21acumFHXv1dgNVQIAAACobW4L3UePHpXNZlNkZKRTe2RkpNLS0s573NjYWL3++utatmyZFi5cqH379unKK69UXl55wElLS5O3t7eCg4NrtN3i4mLl5uY6vVC/+Pp5y2w2KT+/2Kk9P79Y/gGVJ1GrCU9PsxqE+alR4yBdM7SNohoGaPV3+yv1+2VLmkpLberavdHv2h4AAACAi4PbJ1KrbUOGDNGIESPUqVMnxcfH64svvlB2drbef//93zVuUlKSgoKCHK8mTbjftr7x9DQrulGgftuT5Wiz2w39tidLTZrW7qXehiHZyuyV2jesP6Q27SLlV8VM6QAAAADqHreF7rCwMHl4eFSaNTw9Pf2Mk6TVVHBwsC6//HLt2bNHkhQVFaWSkhJlZ2fXaLtTpkxRTk6O43Xo0KFaqxEXj75XNdNP6w5p40+HlZGer39/9ItKSsrUvWf55d4fvPuzvvpip6N/WZldqUdylXokVzabXbk5RUo9kqusowWOPl99sVP7fjum48cKlZaaq6++2Kn9v2Wpc7dop21nHS3QgX3H1J0J1AAAAIB6w20TqXl7e6t79+5KTk7WsGHDJEl2u13JycmaNGlSrW0nPz9fe/fu1Z/+9CdJUvfu3eXl5aXk5GQNHz5ckrRr1y4dPHhQvXv3rnYci8Uii4Wzj/Vdxy7RKigoUfKXvyo/r0QNowM07o5ejsvLs7NPyGQ62T8vt0jz556cHf/7b/fp+2/3KaZ5qO64q3xSvvz8En343s/Kyy2W1eqpyIYBGndHT7W83PkZ3Bt+PKzAIKtaXh7m+h0FAAAAcEG4dfbyxMREjRs3Tj169FCvXr00d+5cFRQUOGYzHzt2rBo1aqSkpCRJ5ZOvbd++3fH1kSNHtHnzZvn7+6tly5aSpPvvv1/XX3+9mjZtqpSUFE2fPl0eHh4aPXq0JCkoKEi33367EhMTFRoaqsDAQN1zzz3q3bs3M5dDknRF3xhd0TemymUVQbpCSKivHn9m6BnHu+mWTue03WuGtNY1Q1qfU18AAAAAdYNbQ/fIkSOVmZmpadOmKS0tTV26dNGyZcsck6sdPHhQZvPJK+BTUlLUtWtXx/tnn31Wzz77rPr376+VK1dKkg4fPqzRo0crKytL4eHh6tevn9auXavw8JNnFZ9//nmZzWYNHz5cxcXFio+P14IFCy7MTgMAAAAALhkmwzAMdxdRF+Xm5iooKEg5OTkKDAystt/QjnddwKrqni+2LnR3CQAAAABQY+eaCevd7OUAAAAAAFwsCN0AAAAAALiIW+/pBnDp+nH9Ia354YDy80sUGeWvwUNaq1HjoCr7ZmTk69sVe5WakqecnCJdE3+5Yntf5tTnpx8Pa8OPh5WdfUKSFB7hr6v6N1PLVidngy8rtWn5V7u17Zd0lZXZ1aJlqIZc20b+PBcdAAAALsKZbgAX3LZf0rT8y1911YDmmvDnXoqMDNDitzepIL+kyv5lpTaFhPhqYFxL+ft7V9knMNCigXEtdcefY3XHxF6KaRaiJe/+rIyMfEefr778Vb/uytTwER01LqG78vJKtHTJFpfsIwAAACARugG4wdo1B9W1WyN16Rqt8Ah/XXtdG3l5eWjzppQq+0c3ClLcNa3UoWOUPDyq/rF1eetwtbo8TA0a+KpBmJ8GDmopb28PHTmcI0kqKirTpo0p+kP85WrWPFQNowN1w43tdPhQjg4fynHZvgIAAODSRugGcEHZyuxKTclTs+ahjjaT2aRmzUN1+HB2rWzDbjf0y9Y0lZba1Ph/l6ynpuTKbjfU/JTthoX7KSjIWmvbBQAAAE7HPd0ALqjCwlIZhlHpMnE/P28dPVrwu8ZOT8/Xa6/8qLIyu7y9PTRiZGeFR/hLkvLzS+ThYZLVx6vSdvOruawdAAAA+L3O60z3W2+9pb59+yo6OloHDhyQJM2dO1effvpprRYHADUR1sBXE++M1e0Teqp7z8b69yfblHnKPd0AAADAhVbj0L1w4UIlJiZq6NChys7Ols1mkyQFBwdr7ty5tV0fgHrG19dLJpOp0tnlgoKSaidJO1cenmaFNvBVw+hADYprqcjIAK1fd0iS5O/vLZvNUNGJ0lrfLgAAAFCdGoful156Sf/85z/1yCOPyMPDw9Heo0cPbd26tVaLA1D/eHia1TA6QPv3HXO0GXZD+347psaNg2t1W4ZhqKzMLklqGB0os9mkfads9+jRAuXkFNX6dgEAAIAKNb6ne9++feratWuldovFooKC33c/JoBLwxW9L9OnH29Xw+hARTcK0vq1B1VaalPnrg0lSZ989IsCAq0aFNdSUvnka5mZ5T9fbDa78vKKlZaaJ29vD4U28JUkJX+9Ry1bNlBQkFXFJTb9sjVN+/cf15g/lf+8slo91bVbtJZ/uVs+Pl6yWDy17Itdatw4SI2bVP18cAAAAOD3qnHobtasmTZv3qymTZs6tS9btkxt27attcIA1F/tO0SpsKBU3674Tfn5xYqMCtAfb+0qf3+LJCk3p0gmk8nRPy+vWP/8xzrH+zWrD2jN6gNq2jRYYxN6SJIKC0r06cfblJ9fLIvFU5GRARrzp65q3qKBY71r4i+XybRbS5dskc1mV/MWDTT02jYXaK8BAABwKapx6E5MTNTdd9+toqIiGYah9evX691331VSUpJeeeUVV9QIoB7qGdtEPWObVLmsIkhXCA7x0dQZcWcc7/ob2511m55eHhpybRsNIWgDAADgAqlx6L7jjjvk4+OjRx99VIWFhfrjH/+o6OhovfDCCxo1apQragQAAAAAoE46r+d0jxkzRmPGjFFhYaHy8/MVERFR23UBAAAAAFDnnddEamVlZWrVqpV8fX3l61s+idHu3bvl5eWlmJiY2q4RAAAAAIA6qcaPDBs/frxWr15dqX3dunUaP358bdQEAAAAAEC9UOPQvWnTJvXt27dS+xVXXKHNmzfXRk0AAAAAANQLNQ7dJpNJeXl5ldpzcnJks9lqpSgAAAAAAOqDGofuq666SklJSU4B22azKSkpSf369avV4gAAAAAAqMtqPJHaU089pauuukqtW7fWlVdeKUn67rvvlJubq2+++abWCwTOxbWDp7q7hIvaf5Y95u4SAAAAgEtSjc90t2vXTlu2bNEtt9yijIwM5eXlaezYsdq5c6c6dOjgihoBAAAAAKiTzus53dHR0XryySdruxYAAAAAAOqV8wrd2dnZWr9+vTIyMmS3252WjR07tlYKAwAAAACgrqtx6P7ss880ZswY5efnKzAwUCaTybHMZDIRugEAAAAA+J8a39P9t7/9Tbfddpvy8/OVnZ2t48ePO17Hjh1zRY0AAAAAANRJNQ7dR44c0b333itfX19X1AMAAAAAQL1R49AdHx+vn376yRW1AAAAAABQr9T4nu5rr71WDzzwgLZv366OHTvKy8vLafkNN9xQa8UBAAAAAFCX1Th0T5gwQZI0a9asSstMJpNsNtvvrwoAAAAAgHqgxqH79EeEAQAAAACAqtX4nm4AAAAAAHBuanymW5IKCgr07bff6uDBgyopKXFadu+999ZKYQAAAAAA1HU1Dt2bNm3S0KFDVVhYqIKCAoWGhuro0aPy9fVVREQEoRsAAAAAgP+p8eXlkydP1vXXX6/jx4/Lx8dHa9eu1YEDB9S9e3c9++yzrqgRAAAAAIA6qcZnujdv3qx//OMfMpvN8vDwUHFxsZo3b66nn35a48aN00033eSKOgFcBOLGPObuEi5qX78z1d0lAAAA4CJT4zPdXl5eMpvLV4uIiNDBgwclSUFBQTp06FDtVgcAAAAAQB1W4zPdXbt21Y8//qhWrVqpf//+mjZtmo4ePaq33npLHTp0cEWNAAAAAADUSTU+0/3kk0+qYcOGkqQnnnhCISEhuuuuu5SZmal//OMftV4gAAAAAAB1VY3PdPfo0cPxdUREhJYtW1arBQEAAAAAUF/U+Ez3wIEDlZ2dXak9NzdXAwcOrHEB8+fPV0xMjKxWq2JjY7V+/fpq+27btk3Dhw9XTEyMTCaT5s6dW6lPUlKSevbsqYCAAEVERGjYsGHatWuXU58BAwbIZDI5ve68884a1w4AAAAAwJnUOHSvXLlSJSUlldqLior03Xff1WisJUuWKDExUdOnT9fGjRvVuXNnxcfHKyMjo8r+hYWFat68uWbPnq2oqKgq+3z77be6++67tXbtWi1fvlylpaW65pprVFBQ4NRvwoQJSk1NdbyefvrpGtUOAAAAAMDZnPPl5Vu2bHF8vX37dqWlpTne22w2LVu2TI0aNarRxufMmaMJEyYoISFBkrRo0SL95z//0auvvqqHHnqoUv+ePXuqZ8+eklTlckmVLnd//fXXFRERoQ0bNuiqq65ytPv6+lYb3AEAAAAAqA3nHLq7dOniuBS7qsvIfXx89NJLL53zhktKSrRhwwZNmTLF0WY2mxUXF6c1a9ac8zhnk5OTI0kKDQ11an/nnXf09ttvKyoqStdff72mTp0qX1/fWtsuAAAAAADnHLr37dsnwzDUvHlzrV+/XuHh4Y5l3t7eioiIkIeHxzlv+OjRo7LZbIqMjHRqj4yM1M6dO895nDOx2+2677771LdvX6fHmf3xj39U06ZNFR0drS1btujBBx/Url279NFHH1U7VnFxsYqLix3vc3Nza6VGAAAAAED9dc6hu2nTpiotLdW4cePUoEEDNW3a1JV11Yq7775bv/zyi77//nun9okTJzq+7tixoxo2bKhBgwZp7969atGiRZVjJSUlaebMmS6tFwAAAABQv9RoIjUvLy99/PHHtbLhsLAweXh4KD093ak9PT29Vu61njRpkj7//HOtWLFCjRs3PmPf2NhYSdKePXuq7TNlyhTl5OQ4XocOHfrdNQIAAAAA6rcaz15+44036pNPPvndG/b29lb37t2VnJzsaLPb7UpOTlbv3r3Pe1zDMDRp0iR9/PHH+uabb9SsWbOzrrN582ZJUsOGDavtY7FYFBgY6PQCAAAAAOBMzvny8gqtWrXSrFmz9MMPP6h79+7y8/NzWn7vvfee81iJiYkaN26cevTooV69emnu3LkqKChwzGY+duxYNWrUSElJSZLKJ1/bvn274+sjR45o8+bN8vf3V8uWLSWVX1K+ePFiffrppwoICHDMsh4UFCQfHx/t3btXixcv1tChQ9WgQQNt2bJFkydP1lVXXaVOnTrV9HAAAAAAAFCtGofuf/3rXwoODtaGDRu0YcMGp2Umk6lGoXvkyJHKzMzUtGnTlJaWpi5dumjZsmWOydUOHjwos/nkyfiUlBR17drV8f7ZZ5/Vs88+q/79+2vlypWSpIULF0qSBgwY4LSt1157TePHj5e3t7e+/vprR8Bv0qSJhg8frkcffbQmhwEAAAAAgLOqcejet29frRYwadIkTZo0qcplFUG6QkxMjAzDOON4Z1vepEkTffvttzWqEQAAAACA81Hje7pPZRjGWUMuAAAAAACXqvMK3W+++aY6duwoHx8f+fj4qFOnTnrrrbdquzYAAAAAAOq0Gl9ePmfOHE2dOlWTJk1S3759JUnff/+97rzzTh09elSTJ0+u9SIBAOdnx/Y0/bIlVSdOlCok1FdX9I5ReIR/lX2PHy/Upg2HlXW0QPn5Jep1xWVq36HyUx3ONuZ/P9+utLQ8p3Vat4lQn35nf5oEAABAfVPj0P3SSy9p4cKFGjt2rKPthhtuUPv27TVjxgxCNwBcJH7bm6X1aw+qT79mCg/307Zf0vTVsp26aURn+fh4VepfVmZXQIBVMc0aaP3aA79rzMtbh6tr98aO956ev+tuJgAAgDqrxr8Fpaamqk+fPpXa+/Tpo9TU1FopCgDw+237JVWXt4lQq8vDFRziqz79msnT06zdv2ZW2T883F89Yy9T8xYN5OFh+l1jenp6yNfX2/Hy9q7x33gBAADqhRqH7pYtW+r999+v1L5kyRK1atWqVooCAPw+NptdWUcLFB0d6GgzmUxq2ChIGel5Z1izdsbcu/eoFr+1QR9/uEU//XhQZWW289sRAACAOq7Gpx5mzpypkSNHatWqVY57un/44QclJydXGcYBABdecVGZDEOVLiP3sXopJ/uES8ds3jJM/v7e8vH11vFjhfpp/UHlZBdp0B8uP6/tAgAA1GU1Dt3Dhw/XunXr9Pzzz+uTTz6RJLVt21br169X165da7s+AEAd07pNhOPr0FBf+fh66csvdio3t0iBgVY3VgYAAHDhnddNdt27d9fbb79d27UAAGqJxeopk0k6caLUqf1EUWmVk6i5cszw8PKZzfMI3QAA4BJ0XqHbZrPp448/1o4dOyRJ7dq104033ihPTybKAYCLgYeHWQ3C/JSakqumMaGSJMMwlHokR23bR13QMY9lFUqSfHy8z2u7AAAAdVmNU/K2bdt0ww03KC0tTa1bt5YkPfXUUwoPD9dnn32mDh061HqRAICaa9+hob5ftVcNwvwUHu6vbdvSVFZmV6tW4ZKkVSv3ytfPSz16XiapfKK07P/dm22zGyosKFVWVoG8PD0UGGQ9pzFzc4v0294sNW4SLIvFU8ePFWr92gOKjApQaANfNxwFAAAA96px6L7jjjvUvn17/fTTTwoJCZEkHT9+XOPHj9fEiRO1evXqWi8SAFBzzVs0UFFRqTZtPKwThaUKbeCrawa3kY9v+aXgBfnFMp3yZLDCwlL9++NfHO9/2ZqqX7amKioqQEOua3dOY5rNJqUcydH2X9JUVmaTr5+3msaEqnPX6Au34wAAABeRGofuzZs3OwVuSQoJCdETTzyhnj171mpxAIDfp137KLWr5tLviiBdISDAooQ7Yn/XmP7+Fg09bVwAAIBLWY1D9+WXX6709HS1b9/eqT0jI0MtW7astcIAAKgrft2VqR3b0nXiRKlCQnzUvVcThYX5Vdv/4IHj2rI5Rfn5JQoItKhLt0Zq1CjIsfzEiVJt3nhEaal5KikpU0RkgLr3bOw0EV1eXrE2bTiszIwC2ex2RUcHqnvPJuc9UR4AAHANc01XSEpK0r333qsPPvhAhw8f1uHDh/XBBx/ovvvu01NPPaXc3FzHCwCA+u7A/mPa+NNhdejUUEOubaPgEB+tSN6jotNmea+QmZGvH77bp+YtwzTkujZq3CRY3638TdnHy++nNwxDq1b+pvz8El01oLmGXNtWfn7e+ubrPSortUmSykptWvH1bknSoD+00jXxrWW3Gfp2xV4ZhnFhdhwAAJyTGp/pvu666yRJt9xyi0z/uxmw4n/w119/veO9yWSSzWarrToBALgo7dyeoRatwtSiZQNJUq8rLlPKkVzt3Zul9h0qX4a/a2eGGkYHql37SElS5y4+SkvN1a+7MtXrisuUl1esrKMFGnp9WwUH+0iSesY20UdLt2r//uNq2SpMmZkFKigo0ZBr28rL20OSdEXfGH2w5Gelp+UpqmHgBdp7AABwNjUO3StWrHBFHQAA1Dk2m13HjhWq3Snh2mQyKaphgI5mFlS5ztHMArVpF+nU1jA6UIcP5UiS7LbyP2R7eJy8GM1kMsnDw6TMjHy1bBUmm80uSTJ7nJwJz8PDJJNJysjIJ3QDAHARqXHo7t+/vyvqAACgzikuLpNhSFYf5/+dWq2eys0pqnKdoqIyWa2n9/dyXI4eGGSVr5+3ft50RL1iL5OHp1m7dmSosLBUJ/7XJyzcT56eZm3eeESduzaSDEObN6XIMKSiE2Uu2FMAAHC+ahy6JamoqEhbtmxRRkaG7Ha707IbbrihVgoDAOBSZDabdFX/5lq75oA+eH+LTCYpqmGgGkafPHtttXqp31XN9eO6g9q1M1Mmk9Q0JlQhoT6S6QyDAwCAC67GoXvZsmUaO3asjh49WmkZ93EDAC4lFounTKbKZ5eLispkrWYWcavVU0VFp/cvdeof2sBXQ69rq5ISm+x2u6xWL335xU6FNvB19GkYHagb/q+DiorKZDZL3t6e+mjpFvn7W2pxDwEAwO9V49nL77nnHo0YMUKpqamy2+1OLwI3AOBS4uFhVmior9LT8hxthmEoLS1PYeFVPzIsLNxPaanOT/hIS82r8hFj3t4eslq9lJtbpGPHCtW4SXClPlarp7y9PZWWmqeiojI1bhxUqQ8AAHCfGp/pTk9PV2JioiIjI8/eGQCAeq5Nuwit+eGAQhv4qkGYr3btyFRZmV3NW5TPZr76h/3y9fFSl26NJEmt20To669+1Y7t6YpuFKQD+4/pWFahesVe5hjz4IHjslg85efnrezsE9rw42E1bhLsdIn53j1ZCgqyymL11NHMfG348bDatI1QYJBVAADg4lHj0H3zzTdr5cqVatGihSvqAQCgTmkaE6qiojJt+TlVRSdKFRLio6sHtpTP/y4XLywocbrNOjzCX32vbKafN6fo500pCgiw6MoBzRUc4uPoc6KwVBt/Ouy4TL1Z81B16Oj8+LG83CL9vOmISkps8vPzVvuOUWrTNuJC7DIAAKiBGofuefPmacSIEfruu+/UsWNHeXk537N277331lpxAADUBa3bRKh1m6oDb9w1l1dqu6xpiC5rGlL9eG0j1PosAbpLt0aOs+cAAODiVePQ/e677+qrr76S1WrVypUrZTKd/Pu9yWQidAMAAAAA8D81Dt2PPPKIZs6cqYceekhmc43nYQMAAAAA4JJR49RcUlKikSNHErgBAAAAADiLGifncePGacmSJa6oBQAAAACAeqXGl5fbbDY9/fTT+vLLL9WpU6dKE6nNmTOn1ooDAAAAAKAuq3Ho3rp1q7p27SpJ+uWXX5yWnTqpGgAAAAAAl7oah+4VK1a4og4AAAAAAOodZkMDAAAAAMBFzvlM90033XRO/T766KPzLgYAAAAAgPrknEN3UFCQK+sAAAAAAKDeOefQ/dprr7myDgAAAAAA6p0aT6QGAHCtPpMec3cJF7XV86a6uwQAAIBzxkRqAAAAAAC4CKEbAAAAAAAX4fJyAABQZ+zff0x79x5TcXGZAgMtat8+SiEhPtX2T0nJ1a5dmTpxolR+ft5q0yZCkZH+juVlZXbt2JGh9PQ8lZTY5OvrpWbNQtW0aYgkqbCwRN98s7fKsbt1a6To6MDa3UEAQL1D6AYAAHVCSkqutm/PUMeOUQoO9tG+fce0fv1BDRjQQhZL5V9pjh0r1KZNR9SmTYQiIvyVkpKjn346pCuvbKbAQKskafv2dB09WqAuXaLl6+ulzMwC/fJLmiwWT0VFBcjHx0txca2cxj148Lj27j2miAj/StsEAOB053V5+VtvvaW+ffsqOjpaBw4ckCTNnTtXn376aY3Hmj9/vmJiYmS1WhUbG6v169dX23fbtm0aPny4YmJiZDKZNHfu3PMas6ioSHfffbcaNGggf39/DR8+XOnp6TWuHQAAXDi//ZalJk2C1aRJsAICLOrYMUpms1mHDmVX2X/fvmMKD/dXixYNFBBgUevWEQoKsmr//uOOPsePn1DjxkEKC/OTr6+3mjYNUWCgVdnZJyRJJpNJVqun0ystLU/R0QHy9OQuPQDA2dX4/xYLFy5UYmKihg4dquzsbNlsNklScHBwtSG4OkuWLFFiYqKmT5+ujRs3qnPnzoqPj1dGRkaV/QsLC9W8eXPNnj1bUVFR5z3m5MmT9dlnn2np0qX69ttvlZKSoptuuqlGtQMAgAvHbjeUk1Ok8HA/R5vJZFJ4uJ+OHz9R5TrHj59QWJifU1t4uL9T/5AQH6Wn5+vEiVIZhqGjRwuUn1+i8PCqz2JnZ59Qbm6xmjQJ/v07BQC4JNQ4dL/00kv65z//qUceeUQeHh6O9h49emjr1q01GmvOnDmaMGGCEhIS1K5dOy1atEi+vr569dVXq+zfs2dPPfPMMxo1apQsFst5jZmTk6N//etfmjNnjgYOHKju3bvrtdde0+rVq7V27doa1Q8AAC6MkpIyGYZksXg4tXt7e6i4uKzKdYqLyyr1t1ic+7dvH6mAAIuSk/foiy92av36Q+rYMVINGvhWOeahQ9ny9/dWaGjVywEAOF2N7+net2+funbtWqndYrGooKDgnMcpKSnRhg0bNGXKFEeb2WxWXFyc1qxZU9OyznnMDRs2qLS0VHFxcY4+bdq00WWXXaY1a9boiiuuOK9tAwCAumf//uM6fvyEevZsLB8fL2VlFWrr1nRZLF5OZ9UlyWaz68iRXLVqFeamai+cAweOa9++YyoutikgwKJ27SIUHFz9hHWpqXnavfuoTpwola+vl1q3Dne6572szK5duzKVnp6v0lKbfHy8FBMTossuC640lmEY+umnIzp6tEDdukUrMjLAFbsIABdMjc90N2vWTJs3b67UvmzZMrVt2/acxzl69KhsNpsiIyOd2iMjI5WWllbTss55zLS0NHl7eys4OLhG2y0uLlZubq7TCwAAXBje3p4ymaTiYptTe0mJrcpJ1CTJYvGs1L+4+GR/m82unTsz1K5dhCIjAxQYaFWzZqGKjg7Qb79lVRovNTVPNptdjRsH1dJeXZxSU3O1Y0emWrYMU58+TRUYaNGPPx6u9oqC48dP6OefU9S4cZD69m2qyMgAbdx4RHl5xY4+O3dm6OjRAnXu3FBXXtlMMTEh2r49Xenp+ZXG27//uEwml+0eAFxwNQ7diYmJuvvuu7VkyRIZhqH169friSee0JQpU/T3v//dFTVeFJKSkhQUFOR4NWnSxN0lAQBwyTCbTQoKsuro0ZNX1VXcg13dI8NCQnyc+kty6m+3GzKM8nvDT2UymWQYlcc7eDBbkZEB1Yb8+mLfvuNq0iRIjRsHKSDAovbtI+XhYdbhwzlV9t+//7jCwvzUvHmo/P0tuvzyMAUGWnXggPOEdY0aBapBA1/5+nrpssvKJ8PLyXG+Hz83t0j79h1Xx45Vz90DAHVRjUP3HXfcoaeeekqPPvqoCgsL9cc//lELFy7UCy+8oFGjRp3zOGFhYfLw8Kg0a3h6enq1k6TVxphRUVEqKSlRdnZ2jbY7ZcoU5eTkOF6HDh06rxoBAMD5ad68gQ4ezNahQ9nKyyvW1q1pstnsjknNNm1K0Y4dJydObdYsVJmZ+dq7N0v5+cXatStT2dknFBNT/gxuLy8PhYb6aseO8rOwhYUlOnQoW4cP5ygqyvmS5oKCEh07Vljl5dD1id1uKDe3SGFhJ+9ZN5lMCgvzVXZ2UZXrZGefqHQPfHi4n1P/kBAfZWQUqKiofMK6rKxCFRSUOE10Z7PZtXlzqtq3j6j3f9gAcGmp0U+0srIyLV68WPHx8RozZowKCwuVn5+viIiIGm/Y29tb3bt3V3JysoYNGyZJstvtSk5O1qRJk2o83rmO2b17d3l5eSk5OVnDhw+XJO3atUsHDx5U7969qx3bYrFUO3kbAKDu6f7ILHeXcFHb8MQ0d5dQSXR0oIqLy/Trr5kqLrYpMNCiXr0ucwS0EydKnS5LDg31VdeujbRrV6Z27cqUn5+3evRo4nhGtyR169ZIO3dmaNOmFMe9xm3ahKtp02CnbR86lC2r1bPSfd71TUmJTYZRfjn/qby9PZSfX1LlOuUT1lXuf+rl6G3bRmjbtnStWPHb/75HJnXsGOk0Id2OHRkKCfHhHm4A9U6NQrenp6fuvPNO7dixQ5Lk6+srX9/zn70zMTFR48aNU48ePdSrVy/NnTtXBQUFSkhIkCSNHTtWjRo1UlJSkqTyidK2b9/u+PrIkSPavHmz/P391bJly3MaMygoSLfffrsSExMVGhqqwMBA3XPPPerduzeTqAEAcJFr1ixUzZqFVrmsT5+mldqiowMVHR1Y7XhWq6e6dIk+63bbtIlQmzY1P8mAcgcOZCs7+4S6dWskHx9PHT9+Qtu2pcti8VRYmJ/S0/OVlVWovn1j3F0qANS6Gl+706tXL23atElNm1b+H1tNjRw5UpmZmZo2bZrS0tLUpUsXLVu2zDER2sGDB2U2n7wCPiUlxWnm9GeffVbPPvus+vfvr5UrV57TmJL0/PPPy2w2a/jw4SouLlZ8fLwWLFjwu/cHAACgLvP29pDJVP6ItlOdfcK66vvbbHb9+mumunVr5JjRPDDQqtzcYu3bd0xhYX7KyipUYWGpvv56t9M4GzemKDTUR7Gxl9XWLgLABVfj0P2Xv/xFf/vb33T48GF1795dfn7Ol1l16tSpRuNNmjSp2svJK4J0hZiYGBlVzWxSgzElyWq1av78+Zo/f36NagUAAKjPzGaTAgOtysoqdFzmXT5hXWGlS+4rBAf7KCur0OkKhKNHCxQcXH4Z/8kJ65zXM5nkmLCuRYtQNWniPCv899/vV9u2EYqIqN+X9AOo/2ocuismS7v33nsdbeWzfBoymUyy2WzVrQoAAICLXLNmIdqyJU2BgVYFB1u1f/9xp0el/fxzqqxWT7VuHS5JiokJ0bp1B7Vv3zGFh/spNTVPOTlF6tChfILa8gnrfLRzZ6bMZrN8fDx17NgJHTmSqzZtysewWDyrPJPu4+MpX1/vC7TnAOAaNQ7d+/btc0UdAAAAuAg0bBiokhKbdu8+6piwrmfPxo5QXFTkPGFdSIiPOneO1u7dmdq166j8/LzUrVsjBQScnIC2S5do7dqVqZ9/TnVMWHf55WH1fjZ4AJDOI3TXxr3cAAAAuHg1bRqipk1DqlxW1f3VDRsGqGHD6mcdt1g81alTwxrVMGRI6xr1B4CLVY1D95tvvnnG5WPHjj3vYgAAAAAAqE9qHLr/+te/Or0vLS1VYWGhvL295evrS+gGAAAAAOB/zGfv4uz48eNOr/z8fO3atUv9+vXTu+++64oaAQAAAACok2ocuqvSqlUrzZ49u9JZcAAAAAAALmW1ErolydPTUykpKbU1HAAAAAAAdV6N7+n+97//7fTeMAylpqZq3rx56tu3b60VBgAAAABAXVfj0D1s2DCn9yaTSeHh4Ro4cKCee+652qoLAAAAAIA6r8ah2263u6IOAAAAAADqnRrf0z1r1iwVFhZWaj9x4oRmzZpVK0UBAAAAAFAf1Dh0z5w5U/n5+ZXaCwsLNXPmzFopCgAAAACA+qDGodswDJlMpkrtP//8s0JDQ2ulKAAAAAAA6oNzvqc7JCREJpNJJpNJl19+uVPwttlsys/P15133umSIgEAAAAAqIvOOXTPnTtXhmHotttu08yZMxUUFORY5u3trZiYGPXu3dslRQIAAAAAUBedc+geN26cJKlZs2bq06ePvLy8XFYUAAAAAAD1QY0fGda/f3/H10VFRSopKXFaHhgY+PurAgAAAACgHqjxRGqFhYWaNGmSIiIi5Ofnp5CQEKcXAAAAAAAoV+PQ/cADD+ibb77RwoULZbFY9Morr2jmzJmKjo7Wm2++6YoaAQAAAACok2p8eflnn32mN998UwMGDFBCQoKuvPJKtWzZUk2bNtU777yjMWPGuKJOAABQB3V+drq7S7io/Xz/THeXAABwsRqf6T527JiaN28uqfz+7WPHjkmS+vXrp1WrVtVudQAAAAAA1GE1Dt3NmzfXvn37JElt2rTR+++/L6n8DHhwcHCtFgcAAAAAQF1W49CdkJCgn3/+WZL00EMPaf78+bJarZo8ebIeeOCBWi8QAAAAAIC6qsb3dE+ePNnxdVxcnHbu3KkNGzaoZcuW6tSpU60WBwAAAABAXVbj0H2qoqIiNW3aVE2bNq2tegAAAIBLQnp6nlJT81RaapOvr7eaNg2Wv7+l2v7HjhXq8OEcFReXyWr1UpMmQQoO9nHqc+JEqQ4dylZeXrEMQ/Lx8VTLlmGyWMp/7S8psenQoWzl5hbJZjNktXoqOjpQoaG+Lt1X4FJW49Bts9n05JNPatGiRUpPT9evv/6q5s2ba+rUqYqJidHtt9/uijoBAABwBv1ef8TdJVzUvh//hLtLcJKVVaiDB7MVExMif3+L0tLytGtXpjp1aigvL49K/fPyirVnT5YjaGdlFWr37qNq3z5Svr7ekqSiojJt356h8HA/NWoUJA8Ps06cKJXZbHKM89tvWbLZDLVqFSZPTw9lZRVoz54stW/vKT8/7wu2/8ClpMb3dD/xxBN6/fXX9fTTT8vb++Q/zA4dOuiVV16p1eIAAACA+igtLU/h4f4KD/eXj4+XYmJCZDablZlZUGX/9PQ8BQVZ1bBhoHx8vNS4cZB8fb2Vnp7v6HP4cLaCg6267LJg+fl5y2r1VEiIj1OIz88vUWSkv/z9LbJaPR3hvKCgxOX7DFyqahy633zzTb388ssaM2aMPDxO/gPu3Lmzdu7cWavFAQAAAPWN3W6ooKBEQUEnLyU3mUwKDLQoP7+4ynXy80sUFGR1agsKsio/vzwsG4ah7OwiWa2e2rkzUxs3HtG2bek6frzQaR1/f29lZRWqrMwmwzCUlVUowzAUGFj9Ze0Afp8aX15+5MgRtWzZslK73W5XaWlprRQFAAAA1FdlZXZJkqen82XkXl4eKioqq3Kd0lKbvLzMp/U3q7TU9r/ldtnthlJT89S4cZCaNAlSTk6Rdu/OUps2ZgUGlgf2li3DtGdPljZuTJHJJJnNJrVqFSar1au2dxPA/9T4THe7du303XffVWr/4IMP1LVr11opCgAAAEDNBQf7KCoqQH5+3oqODlRwsFUZGScvWT98OEc2m12tW4erfftIRUUFaM+eoyos5PJywFVqfKZ72rRpGjdunI4cOSK73a6PPvpIu3bt0ptvvqnPP//cFTUCAAAA9YanZ/l5r7Iym1N7VWezK3h5eai01H5af7vjfm1PT7NMpvLZyk/l4+OlvLzyS9aLisqUkZGvDh2i5Otbfmbb19dbeXnFSk/PV7Nmob9/5wBUUuMz3TfeeKM+++wzff311/Lz89O0adO0Y8cOffbZZ/rDH/7gihoBAACAesNsNsnPz1s5OSfv3zYMQ7m5xdU+Mszf31u5uUVObbm5RfL393Ya8/TL04uKyuTtXR7E7fby0G4y6TSVGgDUonM+0/3bb7+pWbNmMplMuvLKK7V8+XJX1gUAAADUW1FRAfrttyz5+XnL399baWl5stvtCg/3kyTt3Zslb28PNWkSLEmKjAzQzp0ZSk3NdTwyrKCgRDExIU5j7t2bpYAAiwIDLcrJKdLx4yfUtm2EJMlq9ZLF4qn9+4+rSZMgeXp66PjxQuXmFunyy8Mu+DEALhXnHLpbtWql1NRURUSU/6MdOXKkXnzxRUVGRrqsOAAAAKA+atDAV2VlNh05kqPSUpt8fb3VunW443LxkhKb0xnpgACLWrRooMOHc3T4cI6sVk+1ahXmeEa3JIWG+spmsyslJU8HDmTLx6e8T0BA+dlzs9mk1q3DdOhQjn799ajsdkMWi6eaNw9VcLDPBd1/4FJyzqHbMAyn91988YWSkpJqvSAAAADgUhAZGaDIyIAql1WcnT5VaKivQkN9zzhmxbO/q2O1eqlVK85qAxdSje/pBgAAAAAA5+acQ7fJZJLptFkXTn8PAAAAAABOqtHl5ePHj5fFUn5PSFFRke688075+fk59fvoo49qt0IAAAAAAOqocw7d48aNc3p/66231noxAAAAAADUJ+ccul977TWXFTF//nw988wzSktLU+fOnfXSSy+pV69e1fZfunSppk6dqv3796tVq1Z66qmnNHToUMfy6i57f/rpp/XAAw9IkmJiYnTgwAGn5UlJSXrooYdqYY8AAAAAALgIJlJbsmSJEhMTNX36dG3cuFGdO3dWfHy8MjIyquy/evVqjR49Wrfffrs2bdqkYcOGadiwYfrll18cfVJTU51er776qkwmk4YPH+401qxZs5z63XPPPS7dVwAAAADApcXtoXvOnDmaMGGCEhIS1K5dOy1atEi+vr569dVXq+z/wgsvaPDgwXrggQfUtm1bPfbYY+rWrZvmzZvn6BMVFeX0+vTTT3X11VerefPmTmMFBAQ49Tv9/nQAAAAAAH4Pt4bukpISbdiwQXFxcY42s9msuLg4rVmzpsp11qxZ49RfkuLj46vtn56erv/85z+6/fbbKy2bPXu2GjRooK5du+qZZ55RWVlZtbUWFxcrNzfX6QUAAAAAwJmc8z3drnD06FHZbDZFRkY6tUdGRmrnzp1VrpOWllZl/7S0tCr7v/HGGwoICNBNN93k1H7vvfeqW7duCg0N1erVqzVlyhSlpqZqzpw5VY6TlJSkmTNnnuuuAQAAAADg3tB9Ibz66qsaM2aMrFarU3tiYqLj606dOsnb21t//vOflZSU5Hgs2qmmTJnitE5ubq6aNGniusIBAAAAAHWeW0N3WFiYPDw8lJ6e7tSenp6uqKioKteJioo65/7fffeddu3apSVLlpy1ltjYWJWVlWn//v1q3bp1peUWi6XKMA4AAAAAQHXcek+3t7e3unfvruTkZEeb3W5XcnKyevfuXeU6vXv3duovScuXL6+y/7/+9S91795dnTt3PmstmzdvltlsVkRERA33AgAAAACAqrn98vLExESNGzdOPXr0UK9evTR37lwVFBQoISFBkjR27Fg1atRISUlJkqS//vWv6t+/v5577jlde+21eu+99/TTTz/p5Zdfdho3NzdXS5cu1XPPPVdpm2vWrNG6det09dVXKyAgQGvWrNHkyZN16623KiQkxPU7DQAAAAC4JLg9dI8cOVKZmZmaNm2a0tLS1KVLFy1btswxWdrBgwdlNp88Id+nTx8tXrxYjz76qB5++GG1atVKn3zyiTp06OA07nvvvSfDMDR69OhK27RYLHrvvfc0Y8YMFRcXq1mzZpo8ebLTPdsAAAAAAPxebg/dkjRp0iRNmjSpymUrV66s1DZixAiNGDHijGNOnDhREydOrHJZt27dtHbt2hrXCQAAAABATbj1nm4AAAAAAOozQjcAAAAAAC5C6AYAAAAAwEUI3QAAAAAAuAihGwAAAAAAFyF0AwAAAADgIoRuAAAAAABchNANAAAAAICLeLq7AAAAAKCuSPhvortLuKi9NmSOu0sALjqc6QYAAAAAwEUI3QAAAAAAuAihGwAAAAAAF+GebgAAAAD1Vk5OkbKzT8hms8vb21NhYb6yWr2q7Z+fX6xjxwpVVmaXl5eHQkN95efnXWXfzMx85eYWq0EDXwUH+zjai4vLlJVVqOLiMkmSn5+3wsL8ZDabanfnUCdwphsAAABAvZSfX6yjRwsUEuKjxo2D5O3todTUPJWV2avsX1RUqvT0fAUEWNW4cZD8/LyVlpbnCM+nj11UVCYPD+cgXVZmV0pKrry8zGrUKEgNGwaqtNSmjIx8l+wjLn6EbgAAAAD1UnZ2kQIDLQoMtMrb21Ph4X4ymaS8vOJq+/v6eikkxEfe3p4KDfWVxeKp3Nwip35lZTYdPVqoyEh/mUzOobuwsEQmkxQW5idvbw9ZrZ4KC/NTQUGJSkttLttXXLwI3QAAAADqHcMwVFxcJl/fk5eGm0wm+fh4q6iotMp1iovL5OPjfOm5r6+XiopOnuk2DEPp6fkKDi4P8lVtVzI5hfGKy8pPnKh6u6jfCN0AAAAA6h2bzZCkSpd/e3qaHMtOV1Zml4eHc0Ty8DDLZjt5OXp2dpFMJpOCgqxVjuHj4yWbza7jx0/IMAzZbHZlZRU61YRLCxOpAQAAAMA5KC4uU07OCTVuHFzpsvIK3t6eiojwV1ZWgY4dKw/bQUHWSuEflw5CNwAAAIB6pyLknn52uazMqDYAe3o6n9UuX//k2e8TJ0plsxk6cOC4U5+srELl5BSpadMQSVJAgEUBARaVldkdl5bn5BTJy4sLjS9FhG4AAAAA9Y7JZJLF4qnCwlLHI78Mw9CJE6XVXhpusXjqxIlSp8d/FRaWymotj00BAZZK93ynpub+L2RXHtPTszxk5+YWyWRSpXVxaSB0AwAAAKiXgoOtysjIl8VSPot4Tk6RDMNQQIBFkpSenidPT7MaNPBz9D9yJFfZ2Sfk6+ut/PxiFReXKTy8fLmHh7nSPd8mk0keHmZ5e3s42nJyTshq9ZLJZNKJE6XKyipQaKhvpXVxaSB0AwAAAKiX/P0tjknNysrsslg81bBhgOMMdFmZ3enebKvVS5GR/jp2rFBZWYXy8vJQVFSALJaaxaaiojIdO3ZCdrshb28PhYf7O4I+Lj2EbgAAAAD1VlCQj4KCfKpc1qhRUKU2f3+L/P3PPSBX3Md9qsjIgHMvEPUe1zcAAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAiF0Xonj9/vmJiYmS1WhUbG6v169efsf/SpUvVpk0bWa1WdezYUV988YXT8vHjx8tkMjm9Bg8e7NTn2LFjGjNmjAIDAxUcHKzbb79d+fn5tb5vAAAAAIBLl9tD95IlS5SYmKjp06dr48aN6ty5s+Lj45WRkVFl/9WrV2v06NG6/fbbtWnTJg0bNkzDhg3TL7/84tRv8ODBSk1Ndbzeffddp+VjxozRtm3btHz5cn3++edatWqVJk6c6LL9BAAAAABcetweuufMmaMJEyYoISFB7dq106JFi+Tr66tXX321yv4vvPCCBg8erAceeEBt27bVY489pm7dumnevHlO/SwWi6KiohyvkJAQx7IdO3Zo2bJleuWVVxQbG6t+/frppZde0nvvvaeUlBSX7i8AAAAA4NLh1tBdUlKiDRs2KC4uztFmNpsVFxenNWvWVLnOmjVrnPpLUnx8fKX+K1euVEREhFq3bq277rpLWVlZTmMEBwerR48ejra4uDiZzWatW7euyu0WFxcrNzfX6QUAAAAAwJm4NXQfPXpUNptNkZGRTu2RkZFKS0urcp20tLSz9h88eLDefPNNJScn66mnntK3336rIUOGyGazOcaIiIhwGsPT01OhoaHVbjcpKUlBQUGOV5MmTWq8vwAAAACAS4unuwtwhVGjRjm+7tixozp16qQWLVpo5cqVGjRo0HmNOWXKFCUmJjre5+bmErwBAAAAAGfk1tAdFhYmDw8PpaenO7Wnp6crKiqqynWioqJq1F+SmjdvrrCwMO3Zs0eDBg1SVFRUpYnaysrKdOzYsWrHsVgsslgs57JbAAAAAH6Hp76/1d0lXNQe7Pe2u0tADbj18nJvb291795dycnJjja73a7k5GT17t27ynV69+7t1F+Sli9fXm1/STp8+LCysrLUsGFDxxjZ2dnasGGDo88333wju92u2NjY37NLAAAAAAA4uH328sTERP3zn//UG2+8oR07duiuu+5SQUGBEhISJEljx47VlClTHP3/+te/atmyZXruuee0c+dOzZgxQz/99JMmTZokScrPz9cDDzygtWvXav/+/UpOTtaNN96oli1bKj4+XpLUtm1bDR48WBMmTND69ev1ww8/aNKkSRo1apSio6Mv/EEAAAAAANRLbr+ne+TIkcrMzNS0adOUlpamLl26aNmyZY7J0g4ePCiz+eTfBvr06aPFixfr0Ucf1cMPP6xWrVrpk08+UYcOHSRJHh4e2rJli9544w1lZ2crOjpa11xzjR577DGny8PfeecdTZo0SYMGDZLZbNbw4cP14osvXtidBwAAAADUa24P3ZI0adIkx5nq061cubJS24gRIzRixIgq+/v4+OjLL7886zZDQ0O1ePHiGtUJAAAAAKis6ESJThSWym435Olplq+/RV5eHtX2Ly4uU2FBsew2Qx4eZvn6ecvbcjKeFhYUq7i4THabIZNJ8vT0kI+ft9OYhQUlKi0pU1mZXSaTFBrm79J9PF9uv7wcAAAAAFB3FReVqiC/RD5+3goK8ZWHp1l5OSdkt9ur7F9aalN+bpGsVi8FhfjK2+KhvNwilZXZHH08PMzy87coONRXgcE+MnuY/jemccpIhrwtnrL6eLl4D38fQjcAAAAA4LwVnSiVxeolq9VLnp7lYVkmk4qLyqrt7+XtIR9f7/Kz4n4WeXqaVXSi1NHHYvWSt7enPDzM8vT0kK+fRYYh2U4J5r5+Fvn4esvD8+KOtRd3dQAAAACAi5ZhGCors8vb++Rl3yaTSd5eHiottVW5TlmprdKl517eHiorrfrMuGEYKi4qlckkeXhWf8n6xeqiuKcbAAAAAFD3GP+73NtkNjm1m8wmGdWEaLvdkPm0/mazWXa785nxkuIy5eUWOcYLDPKptF5dwJluAAAAAMBFx8vbw3FPt7d3+X3f1d0nfjEjdAMAAAAAzkvFGW7DaYKz8venn/2uYDabTpsQTbLb7ZXOYptMJnl4mOXl5SH/AKtkUrX3iV/MCN0AAAAAgPNiMpnk6WlWacnJ+7cNw1BpFfdtV/Cs4n7v0hKbPL3OEk+N8rHrGu7pBgAAAACcN6uPl/LziuXhVT7TeNGJEhmGIYu1PG7m5RbJbDaVz2r+v/652Sd0orBE3t6eKi4uVVmZXX4B5csNw9CJghJ5WTxlNptk2A0VFZU/A/zUZ3nbbHYZhiG7zZAhOR455uFhlsl08dz7TegGAAAAAJw3i9VL9v8FZbvdkKenWQFBPjKby89c2+12mU65yNrLy0P+gVYVFhSrsKBEHh5mBQRa5XnKzOQ2m11FuUWOy9Q9Pc0KCvZx6nOioETFxScvN885fkKSFBhklZf3xRN1L55KAAAAAAB1ko+Pt3x8vKtcFhTsW6nNYvGUxVJ1HDWZTAoI8jnrNv0DrfKvWZluwT3dAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFPdxcAAAAAALjwPlvXz90lXNSuj/2+VsbhTDcAAAAAAC5C6AYAAAAAwEUI3QAAAAAAuAihGwAAAAAAFyF0AwAAAADgIoRuAAAAAABchNANAAAAAICLXBShe/78+YqJiZHValVsbKzWr19/xv5Lly5VmzZtZLVa1bFjR33xxReOZaWlpXrwwQfVsWNH+fn5KTo6WmPHjlVKSorTGDExMTKZTE6v2bNnu2T/AAAAAACXJreH7iVLligxMVHTp0/Xxo0b1blzZ8XHxysjI6PK/qtXr9bo0aN1++23a9OmTRo2bJiGDRumX375RZJUWFiojRs3aurUqdq4caM++ugj7dq1SzfccEOlsWbNmqXU1FTH65577nHpvgIAAAAALi1uD91z5szRhAkTlJCQoHbt2mnRokXy9fXVq6++WmX/F154QYMHD9YDDzygtm3b6rHHHlO3bt00b948SVJQUJCWL1+uW265Ra1bt9YVV1yhefPmacOGDTp48KDTWAEBAYqKinK8/Pz8XL6/AAAAAIBLh1tDd0lJiTZs2KC4uDhHm9lsVlxcnNasWVPlOmvWrHHqL0nx8fHV9peknJwcmUwmBQcHO7XPnj1bDRo0UNeuXfXMM8+orKys2jGKi4uVm5vr9AIAAAAA4Ew83bnxo0ePymazKTIy0qk9MjJSO3furHKdtLS0KvunpaVV2b+oqEgPPvigRo8ercDAQEf7vffeq27duik0NFSrV6/WlClTlJqaqjlz5lQ5TlJSkmbOnFmT3QMAAAAAXOLcGrpdrbS0VLfccosMw9DChQudliUmJjq+7tSpk7y9vfXnP/9ZSUlJslgslcaaMmWK0zq5ublq0qSJ64oHAAAAANR5bg3dYWFh8vDwUHp6ulN7enq6oqKiqlwnKirqnPpXBO4DBw7om2++cTrLXZXY2FiVlZVp//79at26daXlFoulyjAOAAAAAEB13HpPt7e3t7p3767k5GRHm91uV3Jysnr37l3lOr1793bqL0nLly936l8RuHfv3q2vv/5aDRo0OGstmzdvltlsVkRExHnuDQAAAAAAztx+eXliYqLGjRunHj16qFevXpo7d64KCgqUkJAgSRo7dqwaNWqkpKQkSdJf//pX9e/fX88995yuvfZavffee/rpp5/08ssvSyoP3DfffLM2btyozz//XDabzXG/d2hoqLy9vbVmzRqtW7dOV199tQICArRmzRpNnjxZt956q0JCQtxzIAAAAAAA9Y7bQ/fIkSOVmZmpadOmKS0tTV26dNGyZcsck6UdPHhQZvPJE/J9+vTR4sWL9eijj+rhhx9Wq1at9Mknn6hDhw6SpCNHjujf//63JKlLly5O21qxYoUGDBggi8Wi9957TzNmzFBxcbGaNWumyZMnO92zDQAAAADA7+X20C1JkyZN0qRJk6pctnLlykptI0aM0IgRI6rsHxMTI8Mwzri9bt26ae3atTWuEwAAAACAmnDrPd0AAAAAANRnhG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4CKEbAAAAAAAXIXQDAAAAAOAihG4AAAAAAFyE0A0AAAAAgIsQugEAAAAAcBFCNwAAAAAALkLoBgAAAADARQjdAAAAAAC4yEURuufPn6+YmBhZrVbFxsZq/fr1Z+y/dOlStWnTRlarVR07dtQXX3zhtNwwDE2bNk0NGzaUj4+P4uLitHv3bqc+x44d05gxYxQYGKjg4GDdfvvtys/Pr/V9AwAAAABcutweupcsWaLExERNnz5dGzduVOfOnRUfH6+MjIwq+69evVqjR4/W7bffrk2bNmnYsGEaNmyYfvnlF0efp59+Wi+++KIWLVqkdevWyc/PT/Hx8SoqKnL0GTNmjLZt26bly5fr888/16pVqzRx4kSX7y8AAAAA4NLh9tA9Z84cTZgwQQkJCWrXrp0WLVokX19fvfrqq1X2f+GFFzR48GA98MADatu2rR577DF169ZN8+bNk1R+lnvu3Ll69NFHdeONN6pTp0568803lZKSok8++USStGPHDi1btkyvvPKKYmNj1a9fP7300kt67733lJKScqF2HQAAAABQz7k1dJeUlGjDhg2Ki4tztJnNZsXFxWnNmjVVrrNmzRqn/pIUHx/v6L9v3z6lpaU59QkKClJsbKyjz5o1axQcHKwePXo4+sTFxclsNmvdunW1tn8AAAAAgEubpzs3fvToUdlsNkVGRjq1R0ZGaufOnVWuk5aWVmX/tLQ0x/KKtjP1iYiIcFru6emp0NBQR5/TFRcXq7i42PE+JydHkpSbm3vGfSy1lZxx+aXubMfvXJWWFZ+90yWsto5zWWnR2TtdwmrtOJdwnM+kto6zrZjjfCa1dpyL+Pl8JrV1nCWp7ATH+kxq61iXFHKcz6S2jnNRQWmtjFNf1dZxLiwoq5Vx6quzHeeK5YZhnLGfW0N3XZKUlKSZM2dWam/SpIkbqqk/goKqvo0AtSso6Bl3l3BJCFr6pLtLuCQE/ZPjfCEEPZfk7hIuCUFTn3J3CZeMoL885+4SLgmLtcDdJVwSZuh9d5dwiQg6p155eXkKCqq+r1tDd1hYmDw8PJSenu7Unp6erqioqCrXiYqKOmP/iv+mp6erYcOGTn26dOni6HP6RG1lZWU6duxYtdudMmWKEhMTHe/tdruOHTumBg0ayGQyncPeul9ubq6aNGmiQ4cOKTAw0N3l1Fsc5wuD43xhcJwvDI7zhcFxvnA41hcGx/nC4DhfGHXxOBuGoby8PEVHR5+xn1tDt7e3t7p3767k5GQNGzZMUnmYTU5O1qRJk6pcp3fv3kpOTtZ9993naFu+fLl69+4tSWrWrJmioqKUnJzsCNm5ublat26d7rrrLscY2dnZ2rBhg7p37y5J+uabb2S32xUbG1vldi0WiywWi1NbcHDwee65ewUGBtaZD3JdxnG+MDjOFwbH+cLgOF8YHOcLh2N9YXCcLwyO84VR147zmc5wV3D75eWJiYkaN26cevTooV69emnu3LkqKChQQkKCJGns2LFq1KiRkpLKL3P761//qv79++u5557Ttddeq/fee08//fSTXn75ZUmSyWTSfffdp8cff1ytWrVSs2bNNHXqVEVHRzuCfdu2bTV48GBNmDBBixYtUmlpqSZNmqRRo0ad9a8UAAAAAACcK7eH7pEjRyozM1PTpk1TWlqaunTpomXLljkmQjt48KDM5pOTrPfp00eLFy/Wo48+qocfflitWrXSJ598og4dOjj6/P3vf1dBQYEmTpyo7Oxs9evXT8uWLZPVanX0eeeddzRp0iQNGjRIZrNZw4cP14svvnjhdhwAAAAAUO+5PXRL0qRJk6q9nHzlypWV2kaMGKERI0ZUO57JZNKsWbM0a9asavuEhoZq8eLFNa61LrNYLJo+fXqly+RRuzjOFwbH+cLgOF8YHOcLg+N84XCsLwyO84XBcb4w6vNxNhlnm98cAAAAAACcF/PZuwAAAAAAgPNB6AYAAAAAwEUI3QAAAAAAuAihGwAAAAAAFyF0AwCAOs9ut0uSysrK3FwJcP4qPscA6hdCN4CLis1mc3cJAOqQw4cPa/Xq1TKbzVq6dKnmzZun0tJSd5dV75waBrOzs91XSD1nNpf/av7SSy/p4MGDkgjirsDDm9zrUjz+hG7gHFX8gEhNTXVzJfVXdna2PDw8JEnvvvuu9u/f796C6il+gUN9UVBQoL/97W965JFH9Pjjj2vkyJEKDQ2Vl5eXu0urdyrC4MMPP6z58+crLy/PzRXVX6WlpZo3b54ee+wxSSePPWqH3W6XyWRyei/xR39Xqfj9edOmTVq+fLkkOR3/SwX/iuuwig9xYWGhcnJyqlyG2mMymfTee++pXbt2+u233zjGtey7775T48aNlZmZqfvvv18PPfSQPD093V1WvWO32x2/wH3yySdasGCBFi1apG3btrm5svqHP264np+fn+6++27l5ORo2rRpevjhhzV27FgZhsHP6Fpy6nH85ptv9Prrrys+Pl4BAQFurKp+8/Ly0sSJE7Vnzx5lZmZK4ve62lTx/8Dnn39e48eP17hx47Rz507HH/1RewzDkMlk0kcffaQbbrhBq1ev1m+//ea0/FJB6K6jKj7En332mUaNGqUuXbpowoQJWrBggaRL8y9IrlLxA6GgoECrVq3SjBkz1Lx5c45xLWvZsqUGDRqk1q1b65VXXtHKlSvVuHFjd5dV71T8svH3v/9df/nLX5ScnKxFixZp/PjxeuWVV9xcXf1x6h83VqxYoTfffFNfffWVdu/e7ebK6o+KP2q0a9dOJpNJbdu21ebNm7Vq1SqZTCaZTKZL6hc6V6n4f93ChQu1fv163XHHHerRowfHtpZU98e5kSNHavPmzVq8eLEkfq+rDace6+nTp+vJJ59UWVmZdu/era5du+rLL790Y3X1k8lk0ldffaWxY8fqkUce0ZQpU9S8eXOn5ZfKzxJCdx1lMpn0+eefa+TIkerbt6/mzZun4uJiPfjgg/ruu+/cXV69YjKZtGbNGl1xxRXauXOnBg4c6O6S6pWKH7YNGzZU165dlZ2dLbPZ7PiLM2cLa9+7776rd999V59++qk+/PBD3XPPPdqyZYvCw8PdXVq9URG4H3zwQSUkJGjBggWaMWOGRo4c6bi8DufPMAyZzWbt27dPAQEB+u9//6t58+bJZrPpiSee0KpVqySdDCrFxcXuLLfOKysr07vvvquHH35YO3furHR5Ls5fxc+Kjz/+WJ999pmjvXHjxrr//vv1wQcf6NChQ+4qr16pONYZGRkqLS3VZ599prffflvLly/X+PHj9X//939atmyZm6usP+x2u4qLi/XGG29owoQJuvPOO1VUVKRNmzZp6tSpmjJlikpLSy+Z4E3oroMMw1Bubq5efvllzZgxQw8++KD69eun5cuX6/bbb9eVV17p7hLrnby8PFksFq1bt04+Pj6SxEQ9teDUX9wKCgr0pz/9Sd9//70GDBig7t27a/v27TKbzcxGXMt2796t/v37q2fPnlq6dKkSExP1wgsv6MYbb1RhYaF+/fVXd5dYL7z22mt68803tXjxYq1du1Y33HCDtm/froKCAneXVqdVXOn173//WwMHDtQbb7yhiIgIXX311br33ntlNps1e/ZsR/B+7LHH9I9//IM/4NXA6b8Ae3p6atmyZbrlllu0fPly/fDDD26qrP4xDENpaWl66KGHHL/PffXVV8rIyNCIESN0+PBhx89kPsO/39KlSxUVFaVPPvlEVqtVkhQQEKDnn39e48aN0/DhwwnetcRsNstiscjHx0dbt27Vxo0bNXnyZP3973/X559/rsWLF+vaa6+VdGlcyUHoroNMJpOsVqvS09PVq1cvHTp0SO3bt9f111+vuXPnSpI+++wzbdiwwb2F1iMDBgxQUlKSmjZtqhEjRqi0tFReXl6Ewd/h1Mtvn3nmGSUlJclms6lPnz564YUXdMUVV6h///769ddfHfd2z507l7/411BVv6QVFBSoZcuWWrt2rW677TY99dRTuvPOO2UYhpYsWaL//ve/KioqckO19cOpk8aMHDlSffr00SeffKInn3xSL774ooYNG6bCwkI+y+fJZDLp008/1ejRo/W3v/1N/fv3dywbMmSI7rvvPnl4eOiOO+7Q9ddfr+nTp6tfv35MRnWOTv1j6P79+7V7924dPnxYvr6+euedd9SzZ0+NHj1aGzdudHOlddepP5dNJpOioqK0atUqffTRRwoJCdGMGTM0YMAA7dmzR40bN9YTTzyhkpISPsO1oFevXrr11lu1e/duHT9+XFL598Nqter5559XQkKChg4dqrVr17q50rqp4v9/W7dudVx5e9VVV0mSYmNjlZ+fr7vuukvr16/X9OnTdeLECRUWFrqt3gvKQJ2yd+9eIysry8jJyTEGDhxoPP7440aLFi2MO+64w7Db7YZhGMaRI0eMP/3pT8a7777raMO5qzhmmZmZRn5+vpGZmWkYhmEUFxcbX331ldGhQwejT58+RnFxsWEYhlFaWuq2WuuDBx54wAgPDzfeeustIyUlxdGekpJiDB061AgKCjJeeeUV4+qrrza6detmlJWVubHausVmszm+Xr16tZGXl2cYhmF8/PHHhslkMkwmk/H+++87+uTn5xt/+MMfjL/97W8XvNa67tSftSUlJYZhGMY999xjzJ8/3/jyyy8Nf39/Y9GiRYZhGEZZWZnxxhtvGP/4xz+MoqIit9Rblx07dszo16+fkZSUZBhG+c/m48ePG2+99ZaxY8cOwzAM46effjJmz55t3Hbbbca2bdvcWW6dcurn+NFHHzViY2ONsLAwY/DgwcZDDz1kGIZhFBUVGYMHDzYaN25sbNiwwV2l1lmn/lxeu3at8d///tf4+eefjdzcXEf7+vXrjRkzZhgtWrQwmjdvbnh7exurV6+utD7OrLpjlZKSYtxwww1GaGiosXXrVsMwTn72CwsLjWeeeYbf7c5DxTH88MMPjcaNGxuzZ882UlNTDcMwjIMHDxrr16936v+Xv/zFGDp0qHHixIkLXqs7ELrrCJvNZuzdu9do0KCBsW7dOsMwDGPRokWGyWQyBg4c6NT34YcfNlq3bm3s27fPDZXWbRU/MD7//HPjqquuMjp16mT07dvXWLZsmWEY5b9Mf/XVV0bnzp2Nfv368Qvz7/T2228bDRs2NLZs2eJoy8vLMw4cOGAYRvkvd+PHjzc6d+5sXH/99Y4wwy8dZ3fqMXrkkUeM7t27G6+88opRWlpq2O12Y+rUqYbFYjGWLl1qHDhwwNi6dasRHx9vdO3alV82fodFixYZX3/9tWEYhjFr1izDYrEYvr6+xquvvuroc/z4cSMuLs6YMWOGu8qs0w4dOmQ0b97c+PDDD43c3Fzj0UcfNa688krDYrEYzZs3Nz7++GNHX35WnJ/HHnvMaNCggZGcnGzs3r3bGDt2rGEymf6/vTuPqzH9/wf+vtukkoqMRITSoFRKJmUd2myNpeySkKURJttYa6zVGIOERhjZM9bUJGu2bI0ZS8lWvghFWrSc8/r90e/cn86EKdsR7+fj4TF1n/ucudyuc93X+7qv633h0qVLAEoDExcXFygrK+P69euKLWwVUnZQIyAgAPXq1UOjRo2gpqYGT09PxMTEyJ1/7do17NmzB40aNcLAgQM/dnGrtLLf/QMHDiAyMhKbN29GRkYGAODp06dwc3NDrVq18Pfff5d7D8APVd7GoUOHoKmpiZUrVyI3N7fc61KpFNeuXYO/vz90dHTk+n+fOw66q5hvv/0WLi4uYrD3448/QhAETJo0CVOmTIG3tze0tbXFGyOrvL1790JTUxOLFi3Cnj174O3tDWVlZURHRwMoDbzj4+NhZGSEbt26Kbi0Vcu/Z14sW7YMLi4uAICUlBT8/PPPaNKkCSwtLeHr6yued//+ffG9fBOsnBkzZqBWrVo4evQonjx5Ih7PzMyEv78/qlWrhnr16sHS0hKdOnUSBzZ4RsHbMTc3h6urq/j74MGDxTY5PT0dt2/fhpOTE2xtbbkuV1LZ4G7w4MHQ0tKCvr4+evfujRUrVgAA2rZtixEjRiiqiJ+FrKwsODk5iYMXMTExqFGjBtauXQsA4lOply9fwt/fn9uKSpDdx8LDw6Gvr49jx44hOzsb+/fvh5OTE9zc3HD8+PFy7/vzzz9hamrKszbewuTJk6Gvrw9bW1tUq1YNDg4OWLNmDQDgyZMn6NGjB+rUqcP95ncklUrx8uVLfPfdd5g4cSKA0oco//zzD4KCghAUFAQAuHLlCry8vGBtbY3Lly8rssgfHQfdn6h/j7bJpjLv3LkT33zzDc6cOSMeX7t2Lbp27YqOHTti9OjR3Ci/g9u3b8PR0RHLly8HUBrsNWrUCM2aNYOSkpI4FbewsBBHjhxBWlqaIotb5YWEhKBx48bw8vKCmZkZPD09MW/ePCxevBhNmzYtV5f5qdWbxcTEyE3T+vvvv2Fubi524p4+fYq///4bS5cuRXJyMgDg4sWLSEhIwIULF8Try8Fg5cmuXUJCAlq2bIn9+/cDKG1TXFxcoKurCwMDA9ja2sLe3p4HNyopLS2t3GDc77//jt9//x25ublinR0+fDimTZvGbUUl/Hsw9NmzZzA1NcW5c+ewf/9+aGlpISwsDEDpve/XX39FYmKi3Hu4Hr/ZqVOncOPGDfH3ESNGYOjQoXLnHD16FK1bt8YPP/wAQP5+l5aWBmNjY57OXwFl6/OWLVtQt25dnDt3DsXFxUhPT8eQIUPQvn17bN68GUBpP8/BwUF8AMDezZAhQzBgwAAkJSVh1KhR6Nq1K0xMTNC0aVN89913AEq/D7Jp518SDro/MWXXtAKlayDKNiAvXrxAixYtMHz4cLnz8vLyAPxvLSF7O3fv3sX06dORlZWF+/fvo1mzZvDx8cHDhw/h7OwMdXV1REVFKbqYVdrixYvl6u/MmTPh6emJtWvXioMYSUlJsLa25kGNSpg1axZ69+4t117cuHEDderUwd69e/HXX39h9OjRMDMzE9cIJiUllfscDlYq5nXXKSMjA46Ojpg0aZLc8ZiYGOzevRtHjx7lwY23kJ2djRkzZqBNmzavzDnw6NEj/Pjjj9DR0cHVq1cVUMKqT9Z2ZGdnw9XVFUOHDoWurq4YcANAamoqevTogV27dimqmFXO7du3YWdnh549e4qB94gRI+Du7g5Avi0JDg6Gnp4enj17JvcZkZGREARBXHrFylu0aFG56zZ37lx06NABUqlUvM537tyBi4sLevbsKZ73+PFjvve9hVfljVq+fDns7OygqqqK/v37Y/v27cjLy8OSJUvg5OSkgFJ+Ojjo/oTMnTsXo0ePFqeOX7lyBTY2NujcuTP+/vtvZGZmAijtvDVs2BBxcXHie2UVnxOnvbv79+8DAKZMmYIePXqIyU0mTJgAPT096Onp4fnz53yt39KWLVugrKyMcePGicdkdV4qlSIvLw9ubm7o1q0b3wQrSRbEJScn48WLF8jLy8PQoUNhaGiI6tWrY/z48WJn2dLSEvPnz1dkcaukyMhIMbkiAGzdulVMkCazbds2qKuri/k3XoXr9pu9qn3Nzs7G/PnzYW1tDX9/f/F4fHw8evfujcaNG/MU0UooWwe3bNkCNzc3sQ2JiIiAIAjo16+feOzZs2dwdXVFx44d+cl2Ja1ZswZdunRBv379cP/+fezYsQOCIODEiRNy523btg1t27aVS6pWVFSEnTt38izGN4iKisKQIUPK1cvAwEC0adNG7GPIXk9ISIAgCDyb7h3I2uiTJ09i2bJlmDJlCo4cOQKpVIr/+7//w8mTJ+XOGzt2LHr16oWCgoIvtv/MQfcn5M8//xSTObx8+RK5ubnYvn07nJyc0LBhQ/Tt2xf79+9HRkYGnJycsHjxYgDcSLwNqVQqfulv3ryJM2fO4PTp0+JMgYKCAjg7O2PChAnieyZMmIAtW7YgKytLIWWuil5XN3fv3g11dXW5wPvFixcIDQ2Fi4sLLC0tOWlaJciWnwDAwYMHUatWLURGRkIikSAzMxPx8fFy00FfvnyJtm3bIiIiQhHFrbIiIyPRtWtXsU4+evQIvXv3hp6eHr799ltERkbi6dOnAAB3d3dMnToVhYWFXIff0pkzZ8T7nEx2djYCAwPRsmVLTJ8+HUDpsonIyEieGVMJZevk4cOH4ePjA2VlZYwcOVJsexctWgQlJSV0794drq6uYnJRXhpRcWWDi/Xr18PR0REeHh64f/8+vv/+e9SsWRMHDhzAnTt3kJ2dja5du6J79+7lgpIvNUipDFl93L9/v/iQKjExEYIgYNmyZXLnHjt2DK1atcK9e/c+ejk/J7t27YK2tjaGDRuGzp07w8rKCoMGDZJrG9LS0jBlyhTo6OiImeK/VBx0fyLK3gATEhIwYMAAcesToHTtmq+vL5SVlfH999/DysoKGhoaYhZGVjlltzUwMzND06ZNYWdnBysrK/Ep1owZM6CpqYnly5fDx8cHderUQWpqqiKLXWWdPn263LHo6Gioq6vj+++/F48FBQVhwoQJ4pMVnn7738p2xrZu3QoA8PDwQIsWLbBx40a57KH5+fm4du0a3NzcOEv5W5J1Jo4fP468vDxIJBLcvXsX7u7uaNeuHUxMTBAbGwtvb29YWVnJJa9jb1Z2Cujjx48xevRomJubIzQ0VO68Fy9ewN3dHbq6uvDz81NEUT8bkyZNQuvWrTF69Gi0adMGdevWxYABA8TAOjo6GtOmTYOvry+WL1/ObfNbKNtG//bbb3B0dET//v1x7tw5TJs2DdWrV0f9+vXRvHlzuQFnDrQrpuyyygsXLsDExAQjRowQA++QkBCoqKhg/vz5OH/+PNLS0uDi4oKOHTvygOg7uHHjBho3bizO9Lp58yY0NTUxdepU8ZxTp06hX79+sLS0/OKSpr0KB90KVPbLXnbk+Pjx49DR0cGIESPKJc04fvw4hg4dCnNzcwiCgDt37nzUMld1srXvQOlIp5aWFsLDw1FYWIh9+/bJjYjeuXMHo0aNgqmpKdq1a8fTFt/SuXPnIAiCuKduWRs2bIAgCJg9e3a51/gpyn8r2ylbunQpVFRUxKd9Hh4e+Prrr7Fhwwax3m/YsAEuLi5wdHTkp1WVVHZ7wLNnz0JVVRVz584VBz6Li4tx5coV+Pr6okWLFujcuTMEQcDSpUsVVeQqpWzHOSoqChMnTsSFCxcwfvx42NnZlbuOwcHBMDMzg6urKx4+fPixi/tZiIuLQ+3ateX2fw4NDUWrVq0wcODA17YR3GZU3r8D7w4dOsDDwwNZWVlITk7Gzp07sWPHDvHa8qBGxeTn54s///nnnwBK74WOjo7w8fERZx6tWbMGenp6MDAwgImJCdq2bcuz6d7RsWPHYG5uDgC4desWjIyM4OPjI74ui1+OHj0qLtv80nHQrWA3b94U96jbuXOnmGY/NjYWRkZGGD58eLnRoZycHNy9e5cD7ko6f/48mjRpIu5fvnjxYnF6871792BkZCQ33VnWED98+FBufRV7s3/fwEpKShASEgI1NTUsWbJE7rXr16/jq6++Khec8Ah/5Zw6dQrjxo0T95OX8fDwQPPmzbFx40aUlJTg5s2biI6O5o5dJZW9TrI1mIGBgWjUqBGCgoKQnp4ud/6xY8ewYsUKuLi48DWugCtXrmDu3LmQSCR4/PgxjI2NxcHPjIwM+Pr6om3btnJtxLRp07Bo0SKxU80q7/fff0e9evXkZmPk5ORg9uzZ0NDQgLe3Nwcm79G/A28HBwd4eHjg1q1bcufxoEbF7NmzR9y2deLEiTAyMkJOTg6kUimWLl2Ktm3bYtSoUWL9Tk1NxdmzZ3Hy5ElOZvkOZPX42LFj6Nq1K1JTU9GgQQOMGjVKrLtnzpzBxIkTefr+v3DQrUD5+fkYMmQIqlevjuDgYAiCgA0bNoivHzp0SAy8y24ezwFJ5V2+fBk1atQQBzUAwMfHB97e3rh//z7q16+PUaNGidd2+/btCA0N5Y5GJZWtm7/++itiY2MhkUggkUiwbNkyCIIgt0bz4cOHGD9+PI4cOcI3v7e0d+9emJubo1GjRnI5IWQ8PT3RokULhIeHy11j7thVTExMDOzs7AAA/v7+sLCwwPPnzwGUBt7169dHUFBQuZ0nyuK6/XqXL1+GIAhYuXIlEhISEBgYiDFjxsjNSkpPT4efnx/Mzc1ha2sLT09PaGlp8XKfSijbNsvuaydOnICZmZlcUlagdBDa0NAQJiYm8Pb25rbiPfp34N2+fXsMHjy43MAd+29//fUXdHR08PXXX0NbW7tcP3np0qX45ptv4OPjI5f8UobrdcW9Ku548OABdHV1IQiCXP4joHQQpHPnzry86l846FaAPXv2iD/fu3cP1tbWUFFRETeOL5t4RxZ4e3t74+LFiwopb1WXnJwMDQ0NzJgxQ+54WFgY+vbtCwMDA4wcORJAacNSVFQEX19fTJw4UW7PY/ZmZQconj17hrp168LS0lLMZikLvJWVleHr64uNGzfCxcUF3bp1Ext0Dk4q79KlS/D09IS6urrcTIKyydW6du2KgQMHKqJ4VZpEIsGhQ4fEbdZ0dHTKJesqG3h/ifuOvot//vkH1atXx5w5cwCUbnsnCAJMTU3x4sULAP/rGGdmZmLHjh3o378/vLy8vviEPJXx78FjWTv78OFDWFtbo3v37nLXMy0tDX379kVgYCCsrKzELMTs/SgbwERERMDOzk5MaskPVSrHw8MDgiCgQ4cOr1wLHxwcDAcHB/Tt21ccLGWVUzZL+dKlS7Fp0yZx67u4uDjo6upi1KhRuHLlCs6fP4/JkyejZs2a3Ea/AgfdH1lSUhL09PTEUc2srCzY2tqiRYsWMDQ0FKeSFxUViTfK2NhYaGlpwdfXV64jzf7bvXv3ULt2bfTv31/ueHh4OAYMGABzc3Po6+uLa9pevHiBGTNmwMDAANevX1dEkau8yZMno3///ujQoQN0dHTQuHFjHDlyRHx9x44dqF+/PqysrNCxY0dOGlMJr5t5ce3aNQwaNAhWVlb47bffxONl2wuetfH2hgwZAkEQYGNjIx4rO5sgKCgIDRs2REBAAI/sV9CVK1dQu3ZtfP311+KxzMxMLFmyBEpKSuLe0GWTq8mUXf/NKm7p0qXo378/+vTpI+5mcP36dRgaGqJbt24ICQlBfHw8vv32WwwYMABZWVmoUaNGuUR27N2Vvd+5ubmhV69eiitMFRYdHY1t27ahXr16cHV1FZeblB3AX7hwIby9vfke+A6io6OhqamJVq1aoWnTpmjTpo24JebOnTuhr6+PBg0aoFmzZmjdujXnQHoNDro/suLiYnHLKVl28qdPn+LGjRvo1asXDAwMxMpatmNx+vRppKSkfPTyVnW3b9+Gra0tevbsKY7WL1iwABoaGvj777+RkZGBRo0awdraGqampnBxcYGBgQHPKnhLa9asgY6ODi5cuICMjAzcu3cP9vb2MDIykptC/vTpU2RmZvIT7koo20nbvHkzgoODERwcLCbyun79OgYPHgx7e3usX79ePLdsO8KdjsqRSCQoLi7Gtm3bEB4ejlatWsHR0VG8jmWnQM+aNQs9e/bkwaMKuHz5MjQ0NNCxY0fUq1dPbmpidna2+MR748aNAP5X9/naVk7Z7/u8efOgr6+PkSNHolOnTlBSUsLvv/8OAEhJSUG/fv3QrFkzNGnSBB06dBATVH3zzTfirgjs/Sq7f7Gnpyc/VPkPb7p/Xbp0CV999RVcXV2RnZ0tHo+Ojgbwv2vN98A3k12nslPvHz9+DH9/f7FfER8fj759+6Jp06Zi4P3o0SOcPXsWV69e5YHnN+CgW0Hu378PJSUljB8/Xjx26dIl9O7dG/Xq1UNycjKA0n0yJ0+ezJ2Nd5CSkgJnZ2f07NlT3PorNjZWfP3BgwfYsmULpk+fjs2bN5dLasIqbvr06XBxcZHbB10ikaBNmzb4+uuvkZCQUK5jwTfB/1b2++/v7w9dXV1YW1ujWbNmqFGjBnbu3AmgdLrukCFD4OjoiJUrVyqquFXa6+qjRCLBgQMH0KJFC7Rv317utYMHDwLg4LAikpKSxMzvJSUlCA8PR+3ateUC72fPnuHHH3+EIAhiYMjeXkZGBubNmycmAczPz8fUqVOhoqKCTZs2iceysrLkErROnz4d9erVE5OPsvfv8ePHaNeuHU/F/Q9l2+XIyEjMmjULo0ePllvuk5ycDAMDA3z77beIjY2Fs7MzWrduLb6X2+X/dubMGbnfL1y4ABsbm3J19OzZs+jTpw+aNGkizhRl/42D7o/o31/4devWQVNTE5MmTRKPXb58GX369IGysjJ69eoFJSUlnqbxHty4cQNdu3YVk9bJ8BPWt/eq4GTcuHFo3ry5+LtsTfwff/wBQRBgYWEhziLgYLvyUlNT4ebmhkuXLiE/Px8FBQUYM2YMNDQ0xO1S/vrrL7i5uWH06NHcyaiksnVy8+bNmDlzJmbPno2kpCQApVPKY2Ji0LJlS9jZ2SE5ORldu3ZF586dOeCuoGPHjsntrf3s2bPXBt5z5syBIAj8pPUdyNpeY2Nj8akUUDoDZurUqVBVVcWWLVvk3nPp0iX06NED9erV41lfHwHnjqm4qVOnol69eujTpw++/fZb1KlTB7t27RJnHcn2jrawsIC9vT0vX6uExMRECIKARYsWiceio6PRoUMHaGlpySWqA0q3g/X09ISenh7Onz//sYtbJXHQ/ZHIvvBnz55FTEwMcnNzAZRu2VGtWjX4+/uL52ZkZOCXX36Bn5+fOAWdvbubN2+iW7ducHFxEUf8AW6M30bZ4CQ+Pl7Mmv3PP//gq6++wpQpU+TOj4uLw6RJk9CmTRsxEzT7b2Xr5qZNm2Bubo527dohKytL7t9g8ODBMDY2Fre2u337No/uv4OAgAAYGRnBxcUFffr0gZaWljioUVhYiCNHjqB169YwMjKS2/Ocr3XlyK7X8+fPXxl4Z2Vl4aeffsLVq1cVVcQqR/a9l/33/v37GDt2LJSVlfHHH3/IvVZcXIwZM2ZAEATEx8fLfc7KlSs5rwn7pISHh6N+/friQNDRo0chCAJq166NqKgosV/98uVLXLt2jbcFq6QHDx4gMDAQurq6coH3gQMH0LZtW1hbW5drExITEzFs2DDeSaKCOOj+CGQdi127dkFPTw8//fSTOIW5qKgImzZtgpqamlzgDfCTwA9BNtXcycmJM7K+pbKBxbRp02BhYYHw8HDk5OTgxYsXWLZsGZo2bYpx48bhyZMnSE1NhYuLC3788Ucxk7wsgGGvV/b7f/fuXYSGhsLKygp169YVk3jJnpCcPn0ahoaGuHDhwms/g1VMeHg4GjRoID7djoqKgiAIUFFRkVsfWFhYiIsXL3LH7j0pG3iX3dqRBzIqbsuWLfDy8sKNGzfEAAQozVI+ZMgQaGhoiAnUZNe1qKgIYWFhXH/ZJy03NxeLFy/GunXrAAC7d++GtrY2Nm3ahOHDh6N27drYtm1buQzlfA+snNzcXAQHB0NHRwfLly8Xj+/duxdOTk6wt7cvl1+KZ2pUHAfdH0l8fDy0tbWxdu1auay3shvfhg0boKGhgdGjRyuqiF+MlJQUdO/eHW3btsXp06cVXZwqa+7cudDX18exY8fkGt2CggKsXbsWBgYG0NXVRf369WFpaYmSkhJcvXoVxsbGYs4C9mplAw1fX18MHToU6enpiIiIgKGhIXr06CG3Nv7y5cuoX78+zp07p4jifjaeP3+OgIAAsWO3b98+aGtrIzQ0FCNHjoSamhoOHTpU7n3csXs/nj9/jrVr10IQBEydOlXRxalSnj9/jiZNmkBfXx/m5ubw9vaWS6iYl5cHT09PaGhoiAPO/x7Q4MCbfSpetVzn/PnzyMjIQEpKCpo3b45ly5YBKF2HLAgCBEEot+c8qxjZPSwxMRFz5sxB/fr1IQiC3M4Fe/bsQbdu3dC+fXueffSWOOj+SMaPHy/uk5uXl4dz585h/PjxmDx5srgWYu3atfjqq6/w6NEjRRb1i3Dt2jX07dsXd+/eVXRRqoSNGzeK++YCpdOXra2tsX//fgCl05ISExMxZcoUcf1lXl4e9u3bh5MnT4qZMKdOnQpLS0s8fPjw4/8lqqCMjAzY2Njg6NGjAEqnNq9btw7m5ubo1KkTzp49iyNHjsDV1RU2NjYc/FXSq65XcnIy0tLSkJKSAhMTE3G0f9++fWLHTvbvwd6/Z8+eITIyUtwHllVMSUkJpk+fjtWrV+PChQtYunQpdHR0MGDAACxcuBBFRUV4/PgxfH19oaWlhYSEBEUXmbFXKtsuv6qNPnDgAFq3bi1OaT558iRmzpyJhQsX8sDRO/jjjz+goaGB+fPnIzAwEN27d4empiYWLlwonrNv3z60bdsWTk5OvHXjWxAAgNgHA4AEQaAJEyZQWloajR07lrZv306PHz+mBw8ekIGBAT179owOHjxIWlpaVFBQQNra2oou9hehqKiI1NTUFF2MT96OHTsoKCiILl26REpKSkRElJOTQ+3btyd3d3fq0qULrV69mq5evUrq6up05swZ+uWXX2jChAniZ/z1118UFhZGW7ZsoaNHj5KlpaWC/jZVx8KFC+nMmTOkpaVF69ato+rVqxMR0cuXLykqKopmz55NT548oe+++47q1atHgYGBVL16dZJIJKSsrKzg0n/6ZG0zEVFUVBRpaGhQr169xGN//PEHLV68mA4cOEB6enp08uRJ+v3336l169bk5eVFKioqiiz+Z63svw2ruJiYGPLw8KCTJ0+ShYUFvXz5khYsWEBBQUFkbW1N/fv3J2tra1qzZg1lZWVRfHy8oovMmJyy3/1ly5bR8ePHqWbNmmRubk6TJk0iIqLIyEgaN24cxcXFkYGBAX3//fdkaGhIq1evJiKikpISbp8rKT8/n/r160fNmzenpUuXEhFRRkYGRURE0JIlSygoKIj8/f2JiOjQoUPUvHlzMjIyUmSRqyQlRRfgc1R2HEPWeLi6utKjR4/Iy8uLJBIJjR07li5fvkweHh6koqJC6urqpKqqygH3R8QBd8X069ePLl68SEpKSpSYmEjZ2dmkpqZGXbp0oT179lCnTp2oTp06tGjRIjp16hT179+fbt++LfcZDx8+pOrVq1NiYiIH3K8hlUrFnwGQhoYGxcfHU3JystiOSCQSUldXp0GDBtHcuXPJxsaGCgsLacGCBVS9enUqKCjggLsCpFKpeE3v3LlDkyZNopUrV9Lhw4fFc/Lz8+ns2bN0584devLkCS1ZsoSKi4vJx8eHVFRUqKSkRFHF/+xxwP12XFxcaMiQIRQeHk5EROrq6rRr1y7q1asXdezYkY4cOULdunWjtm3bUlxcnIJLy5i8sgF3YGAgzZ49m+rUqUN5eXk0Z84ccnd3J4lEQsOHD6d27dpRhw4dqHPnzpSRkUG//vqr+DkccFeeIAh09+5dkkgk4rH69evTiBEjyN7eniZPnkwLFiwgIiJnZ2cOuN+Wwp6xf6Zk609OnTqFVatWYfr06eKWX9nZ2eI6CNl5AQEB6NSpU7nkD4x9as6dOwdBEDBv3jwAQE5ODm7cuFFufXa7du0QFBRU7v2cbKNiHjx4AKA0A2tERARUVVUxc+ZM8XXZVP2CggKEh4ejdevWGDx4MF/ft/DDDz/Ay8sLFhYW0NTUhJWVFWJjYyGVSlFQUIA+ffpAEASYmJigZcuWnKWcffLWrVsn7nBgZWWFdu3aif2L9PR0bNu2TZyCy8tR2KdCdl8DStdojxgxQsyoL5FIcPr0aRgYGKBfv37ieXv37kVsbKz4Xp5aXjn/XjcfEBAAFxeXconSpk6dikaNGsHY2BiPHz/m+9874KD7A9ixYwdq1KgBBwcHmJqaQkdHBzNmzMDt27fFc5KSkvDDDz9AW1sbly9fVlxhGXuNBw8e4K+//sKmTZtw5coVAEBkZCQEQUBgYKDcQFFubi6Sk5Ph7OyMVq1a8c3vLW3cuBE1a9YUE6IVFxdj1apVUFZWRmBgoHhe2cA7IiICTZo0gbe3t0LKXFWtXr0aurq6uHDhAu7du4e0tDQ0b94cdnZ2ctuD7du3D9HR0dyxY1WGra0tBEFAhw4d8PTp01eew/WYfQrmz58vF8Tt3r0blpaWMDY2Frenkr3+559/QldXF3v37i33OWWDdvZmsuv57zZgx44d+PrrrzF16lS5nBp+fn5YsmQJnj179lHL+TniORjvQCqVimtcZVJSUmjixIn0yy+/0KBBg0hNTY1CQkJo06ZNpKKiQj/88AM9ePCAgoKC6NGjR3TixAmysLBQ0N+AsVeLjo6miIgIunjxIuXn59PLly/J2dmZVq9eTVu3biVPT09SUlKisWPHko6ODu3cuZN2795NxcXFlJSURCoqKry2+C14enpSWFgYDRo0iKKiosjGxoZGjRpFRER+fn4kCALNnDmTlJWVCQCpq6vTgAEDSEVFhRwdHRVc+qrl2rVrZG9vT9bW1mJbnpCQQPb29hQQEECLFi2irl27Uvfu3cX3SCQSnrrIPln4/9Nz/fz8aPHixRQSEkJ6enqvXCPP9Zgp2u7du+mff/4hqVQq9hVq1qxJRkZGdPDgQTp27Bg1a9ZMrLtmZmakra1NOTk55T6L+xoVI2sLEhISaNOmTVRUVEQNGjSgRYsWUd++fenRo0cUFhZG586do8aNG1NBQQHFxMTQ2bNnqWbNmoouftWn2Ji/6pJNy8rIyMDWrVsRFRWFK1eu4M6dO2jYsCEuXbokN3q3ZMkS6OnpidM2bty4IU4jZexTsmbNGujq6iI4OBjx8fHIzs7G/PnzYWJiAlNTU6Snp2Pz5s0QBAELFixAcXExsrOzcfjwYd6zuBL+PUWr7Oizo6MjjI2Nxb2iS0pKEBYWBkEQ5LYB4mlelSd7IjJ69Gg4OjqKx2XT83ft2gVlZWU4Ozu/dmslxj5lGRkZMDAwkMs6zNinpqCgQOwz7N69W/w5KSkJvXr1grW1NbZs2SKen5eXB1NTU6xZs0Yh5a3qZPex6OhoaGtrw8fHR5w63qNHD/H1ffv2Ye7cuXBwcMCAAQN4Nu57xEH3W5A1DMnJyWjcuDGaN28OZWVlmJmZwdfXF02bNsU///wDoLSRkGnQoAGCg4MVUmbGKmLNmjVQU1PDrl27yr22fft2tGzZEo6OjpBKpeK052nTpsltHcHrBP/by5cvxZ9/++033LlzB4B84O3g4IAmTZqIgXdxcTGio6N5QKOSXlcfjx8/DkEQxL1eZXbt2oVBgwahWbNm6N69+8coImPv3fLly1GrVi2xL8LYp6Rsu3zhwgUYGRnB09NTbr/oPn36wMjICAEBAfj555/Rs2dPmJqa8j2wgmTXsuy1vnz5MkxNTbFq1SoApdu/GhgYQBAEtGvXTm6aflFREW8L9p5x0F1JZQNuDQ0NBAQE4P79+9i/fz+6desGW1tbGBoaolWrVnLve/78OaysrBAVFaWAUjP2344cOSKXKE0qlUIqlcrd4FasWIFq1aph586dAIDAwEDY29vzk8BKiI2NxZIlS3DmzBnk5OSgTp06sLa2Rnp6OoD/Bd7Z2dlo1KgR7O3tkZiYKPcZ3OmomLKdja1btyIwMBAzZswQBzIWL14MNTU1LFy4EOnp6UhPT4ebmxuWL1+OpKQkCIKAU6dOKar4jL21mzdvYujQoTwIyj45/66T+fn5WLVqFWxsbDBo0CDx9TNnzqBnz56oXr06unTpgrCwMPE1XsP9ZrLrdPv2bYSHh4t5Yg4ePAh/f38AwL1799C4cWP4+Pjg8OHD0NLSQu/evVFYWKiwcn/uOOh+C/fu3UPt2rXlsigCQFhYGLS1tbFr1y7Y2NjAwsICZ86cQWJiImbNmgV9fX3cunVLQaVm7M1SUlLg6OiIXr164fjx43Kvlb1JmpubY8yYMeLv/86AyV7vt99+g6GhIXx9fcWb4L1799CiRQu0adMG9+7dE8/Ny8uDk5MTBEFA3759FVXkz8KUKVPQsGFD9O7dG4MGDYIgCNi1axeePHmClStXQktLC/Xr14ehoSEsLCzw8uVLcSZTamqqoovP2FuRtckcoLBPRdm+RFhYGNasWYOsrCwUFBRg1apVsLKykgu8z549i759+8LV1VWcgSd7IMBeTXbt/vrrL5iamsLd3R379+8XX798+TKkUql4P5RKpcjNzYWNjQ0EQYCTk5Oiiv7Z432634JEIiFjY2MqLCykkydPisebNGlC1atXJ2NjY1q7di3p6+tTz549aciQIbRz5046dOgQGRsbK7DkjL2eiYkJRUREUGFhIf30009ydVuWyCQnJ4cKCgqoXr16cq/hFYl6mLytW7fS+PHjKTQ0lBYtWkS2trZERNSgQQM6dOgQFRQUkLu7O6Wnp5NUKiUNDQ2qX78+paam0rZt2xRc+qpHto92dHQ0RUVF0Y4dO2j37t00YMAAIiIqLCykWrVq0dixYyk5OZnCwsLE5IHVqlWjqKgo0tbW5uQxrMqStcmcZIp9KmTJhwMCAmjOnDkEgF6+fEnq6uo0bNgwGjVqFF29epWGDRtGUqmU2rRpQ99//z1paGjQihUrKCoqigRB4P7GGygpKdH169epQ4cO9N1339GKFSvIzc1NfL1Vq1aUk5NDt2/fpr59+5IgCKSiokKWlpa0f/9+CgsLU2DpP3OKjvqrqpSUFDg7O6Nbt264evUqXrx4AX19fUyZMkXuvIsXL+LGjRt49OiRgkrKWOXI6raTk1O5RFKXLl1Cx44dERcXJ3ecvVlmZiY6duyIFStWyB1/8eIFzpw5g0uXLuHu3btwcHBAgwYN4OXlBQcHB7Rq1Yqn01VSXFycXL385Zdf4OXlBaB0SxQtLS2Eh4cDAJ49eyaup5e5du0avL29oaurywlkGGPsPYuKioKBgQEuXLggHpO12Xl5eQgLC0Pr1q3h6uoqHj937hy6desGNzc3vHjxQiHlrioKCgrQr18/jBs3Tu54UVERMjIykJKSgry8PLRu3Rq9e/fG7du3MWXKFJiamnKC5w+Mn3S/JRMTE1q+fDkpKyuTr68vGRkZ0aBBg2jp0qVERFRcXExERFZWVmRqakp16tRRZHEZqzBZ3RYEgQIDA+nEiRMkCAKVlJTQzJkzSUtLi7p06UJExKPNlZCZmUmGhobi72FhYeTl5UXffPMNubq60pgxYyghIYF69+5NeXl5ZGxsTElJSaSkpCS3pQp7vaysLBo1ahQ1b96cABARUW5uLj19+pR27txJI0aMoCVLlojbsO3Zs4cWLlxIubm5RFTabmdkZJCamhodP36cWrVqpbC/C2OMVXWHDx8W+8MyqampZG1tTebm5iSRSORe09DQIC8vLxo4cCDVqVNHfN3W1pYWLFhAq1evJi0trY9W/qpIRUWFHj58SGZmZuKx2NhYCggIoObNm1PXrl3J3d2dZs6cSVeuXCEHBwfatm0bbd26lerWravAkn/+BMh6JuytpKam0pgxYygtLY02btxI7du3JyLi6basyktNTSU/Pz9SUlKiGTNmUGhoKF2/fp0uX75Mqqqqr9ynnr3a48ePydrampydnWnAgAG0atUqSklJIQcHB3J3d6fnz5/TpEmTaMqUKeTn5yf33pKSEt5Tt4IA0OnTp2n06NGkoqJCFy9epCtXrtCQIUMoJSWFFixYQP7+/kRUGox7enpS48aN6ZdffhHba4lEQsXFxaSurq7IvwpjjFVpCxcupD179tDp06fl+sOenp50//59OnHiBBGVtrnKysokkUjo1KlTZGlpSdWqVSNVVVVxwJ/vgRWXk5NDdnZ25OjoSJMnT6bo6GjasGEDtWzZktq3b09aWloUHBxMTk5ONH36dEpNTaUmTZpwwP0RcND9Hty8eZMmTJhAAGjWrFnUrl07RReJsfciNTWV/P39KS4ujho3bkxXrlwhVVVVvgm+hcOHD1OfPn2oVq1aVKNGDQoNDaVWrVpRrVq1KDs7mzp37kzdu3enwMBA8T08eFd5UqmUzp49S15eXqSjo0Nnzpyhn376iX799Vfy8/OjXr16UU5ODs2fP58ePnxISUlJpKKiwteaMcbeM1lf4erVq2RsbEzVq1enP/74g0aNGkWLFy8mLy8v8dwHDx6Qr68v+fr6kpOTExHxPfBtJSQkkJOTExkaGlJWVhYtXbqUunTpQk2bNqWioiLq3r07GRgY0IYNGxRd1C8KB93vSWpqKk2aNImePHlCP//8M7Vt21bRRWLsvbh+/TqtWrWKQkNDSUVFhQPud/D48WPKzc0tl1AxOzubevXqRYMHDxanPrOKOXfuHD19+pRcXFzEullSUkIXL14kT09PMjQ0pBMnTtCsWbPowIEDdPnyZbKzs6MaNWrQgQMHSFVVVXzSwhhj7N0VFhZStWrViIgoJiaG3NzcaPPmzdSvXz/KzMykadOmUUpKCg0ZMoS8vLzo9u3bNH36dHr48CGdPn2a2+P3ID09nTIzM6lhw4ZUu3Zt8bhUKiUPDw8yMzOj+fPnExEvFfxYOOh+j65fv06zZs2ikJAQMjIyUnRxGHvvOOB+/x4/fkxeXl705MkTSkxM5M5GJRw5ckTML2BnZ0dmZmbUq1cvsra2JiMjI0pKSqJRo0aRpqYmnTx5koqLi+nUqVNkbGxM9evXJyUlJa7TjDH2HpVdepaSkkKmpqbk5eVFu3fvpvDwcPLw8KDr16/T2rVraf369aSkpES1atWi2rVr09GjR3kg9AMqKiqiwMBA+u233+jo0aNkYmKi6CJ9UTjofs+KiopITU1N0cVgjH3injx5QuvWraOTJ09SZmYmJSYmcmejktLS0mjIkCFUXFxMtWvXJlNTU9q4cSPVqlWLWrZsSZ06dSIdHR368ccfyczMjOLi4uRG9DkvAWOMvT+xsbG0ZcsWioyMJD8/P7py5QrFxcWRqqoqjRw5krZs2UK//fYbeXh4UGFhIWVmZtL58+fpq6++Ijs7O1JWVuaB0A/k999/p6SkJNq2bRvFxMSQlZWVoov0xeHexnvGATdjrCIyMjIoMTGRmjZtSqdOnRLXynPAXXFNmjShDRs2UIMGDUhZWZlGjBhBt27dovDwcCIq3aN7zJgxJAgCHT58WEyiJsMBN2OMvR/FxcV0/fp1On/+PLVu3Zo2bdpE4eHhpKqqSkRE69ato4EDB5KXlxdt27aNJBIJNWjQgNzd3cne3l5MpsYB9/t348YNioiIoPT0dDpy5AgH3ArCT7oZY0xBnj17RjVr1iRBEPgJ9ztISUkhPz8/kkqlNG/ePPrmm2+IqDQr7sGDB+nWrVt0+vRp2rRpk9gBZIwx9n4BIDc3Nzp06BC5u7vTrl27iEh+jbePjw9t376dli1bRoMHD+Y2+SPJzMykatWqUc2aNRVdlC8WB92MMaZgnKH13aWmptKECROIiGjGjBni9o3/VlxczJ08xhh7T2T3L4lEQgUFBbRixQrKycmh2NhYsrS0pIiICCIiys/PJw0NDSIiGjBgAD169IgSEhIUWXTGPioOuhljjH0WZHvLExH9+OOPvH0jY4x9QK/Li5Gfn0/r1q2jiIgIsrGxEQNvqVRKV69epZYtW3JODfbF4aCbMcbYZ0O2t/yjR48oIiKCLCwsFF0kxhj7rAUHB9O5c+dIKpXSpEmTyN7ennJycmjDhg20fv16atGiBYWEhNDgwYOpRo0a4rRzDrzZl4RrOmOMsc+GiYkJLV26lNq3b08tW7ZUdHEYY+yzI5VKxZ/nz59PS5YsoZo1a1JWVhY5OjrS1q1bSVtbm4YNG0a+vr507tw5srKyoufPn9PWrVvF93LAzb4k/KSbMcbYZ4ufpDDG2Idx//59ioiIoM6dO5ODgwMVFBTQvHnzKCQkhDZs2EADBw6kwsJCysrKoqtXr1LHjh15WzD2xeIazxhj7LPFATdjjL1/e/bsIXd3d2rUqBE5OzsTEVH16tUpMDCQiIiGDx9OSkpK5OnpSQYGBmRgYEBExNuCsS8W13rGGGOMMcbYa8lmDcn+a2trS76+vhQeHk4PHjwQz1FVVaWgoCBSVlamgQMHkr6+PnXp0kX8HN4ak32peHo5Y4wxxhhj7JW2bt1KcXFxNG3aNDI0NCRNTU0iInr06BH98MMPtGvXLvrzzz/J3t5e3EKsuLiYIiIiaOTIkfxkmzHioJsxxhhjjDH2Cjk5OWRtbU05OTlUt25datOmDTk4ONDw4cOJqHR7MG9vb9q7dy/FxcVRu3btxMBbhtdwM8bTyxljjDHGGGOvoKmpSf3796eGDRuSra0tJSQkkL+/P8XFxZGFhQVNnjyZfv31V9LV1SVnZ2fau3cvderUSe4zOOBmjJ90M8YYY4wxxl4jJiaGPDw86OTJk2RhYUEvX76kBQsWUFBQEFlbW1P//v3J2tqa1qxZQ1lZWRQfH6/oIjP2yeGgmzHGGGOMMfZa48aNIyKilStXEhFRixYtyNTUlJo0aUL//PMPxcbGUnBwME2cOJF3jWDsFXi+B2OMMcYYY+y1rK2taf369ZSdnU1dunQhXV1d2rBhA2lra1NGRgadOnWKvvvuO7kM54yx/+En3YwxxhhjjLE3atOmDZ0/f57at29P0dHRpKenV+4cTprG2KvxMBRjjDHGGGPslWTP5/z8/KhFixYUEhJCenp69KrndhxwM/ZqHHQzxhhjjDHGXkm2/VenTp3o6dOn9Oeff8odZ4z9Nw66GWOMMcYYY29kaGhI06dPp+DgYLp69aqii8NYlcJzQBhjjDHGGGP/ydXVlc6fP09mZmaKLgpjVQonUmOMMcYYY4xVCAASBIEkEgkpKysrujiMVQkcdDPGGGOMMcYYYx8Ir+lmjDHGGGOMMcY+EA66GWOMMcYYY4yxD4SDbsYYY4wxxhhj7APhoJsxxhhjjDHGGPtAOOhmjDHGGGOMMcY+EA66GWOMMcYYY4yxD4SDbsYYY4wxxhhj7APhoJsxxhj7TAwfPpwEQSj35+bNm+/82ZGRkaSjo/PuhWSMMca+MCqKLgBjjDHG3h9nZ2dav3693DF9fX0FlebViouLSVVVVdHFYIwxxj4KftLNGGOMfUaqVatGdevWlfujrKxMe/bsIWtra1JXV6fGjRvTvHnzqKSkRHxfaGgomZubk6amJjVo0IDGjh1Lubm5RER09OhR8vLyoufPn4tPz+fOnUtERIIg0B9//CFXBh0dHYqMjCQiojt37pAgCLRt2zbq0KEDqaur0+bNm4mIaN26dfT111+Turo6mZmZ0apVq8TPKCoqovHjx5OBgQGpq6tTw4YNaeHChR/uwjHGGGMfCD/pZowxxj5zJ06coKFDh9Ly5cvJ0dGR0tLSaNSoUURENGfOHCIiUlJSouXLl5OxsTHdunWLxo4dSwEBAbRq1Sqyt7enZcuW0ezZs+nGjRtERKSlpVWpMkybNo1CQkLIyspKDLxnz55NK1asICsrK7p06RL5+PiQpqYmDRs2jJYvX0579+6l7du3k5GREaWnp1N6evr7vTCMMcbYR8BBN2OMMfYZ2b9/v1xA7OLiQtnZ2TRt2jQaNmwYERE1btyYAgMDKSAgQAy6J06cKL6nUaNGFBQURGPGjKFVq1aRmpoa1axZkwRBoLp1675VuSZOnEjfffed+PucOXMoJCREPGZsbExXr16l8PBwGjZsGN27d49MTEzIwcGBBEGghg0bvtX/lzHGGFM0DroZY4yxz0inTp0oLCxM/F1TU5MsLCwoMTGRfvrpJ/G4RCKhly9fUn5+PmloaFB8fDwtXLiQrl+/Tjk5OVRSUiL3+ruysbERf87Ly6O0tDTy9vYmHx8f8XhJSQnVrFmTiEqTwnXt2pWaNWtGzs7O1L17d+rWrds7l4Mxxhj72DjoZowxxj4jmpqa1LRpU7ljubm5NG/ePLknzTLq6up0584d6t69O/n6+tJPP/1Eenp6dPLkSfL29qaioqI3Bt2CIBAAuWPFxcWvLFfZ8hARrV27luzs7OTOU1ZWJiIia2trun37NsXExFB8fDz179+fvv32W9q5c+d/XAHGGGPs08JBN2OMMfaZs7a2phs3bpQLxmUuXLhAUqmUQkJCSEmpNMfq9u3b5c5RU1MjiURS7r36+vr04MED8ffU1FTKz89/Y3m++uorqlevHt26dYsGDRr02vO0tbXJw8ODPDw8qG/fvuTs7ExZWVmkp6f3xs9njDHGPiUcdDPGGGOfudmzZ1P37t3JyMiI+vbtS0pKSpScnEx///03BQUFUdOmTam4uJh+/fVX6tGjByUmJtLq1avlPqNRo0aUm5tLhw8fplatWpGGhgZpaGhQ586dacWKFfTNN9+QRCKhqVOnVmg7sHnz5pGfnx/VrFmTnJ2dqbCwkM6fP0/Z2dk0adIkCg0NJQMDA7KysiIlJSXasWMH1a1bl/cKZ4wxVuXwlmGMMcbYZ87JyYn2799PcXFxZGtrS23btqWff/5ZTE7WqlUrCg0NpcWLF1PLli1p8+bN5bbnsre3pzFjxpCHhwfp6+vTkiVLiIgoJCSEGjRoQI6OjjRw4ECaMmVKhdaAjxw5ktatW0fr168nc3Nz6tChA0VGRpKxsTEREdWoUYOWLFlCNjY2ZGtrS3fu3KGDBw+KT+IZY4yxqkLAvxdiMcYYY4wxxhhj7L3g4WLGGGOMMcYYY+wD4aCbMcYYY4wxxhj7QDjoZowxxhhjjDHGPhAOuhljjDHGGGOMsQ+Eg27GGGOMMcYYY+wD4aCbMcYYY4wxxhj7QDjoZowxxhhjjDHGPhAOuhljjDHGGGOMsQ+Eg27GGGOMMcYYY+wD4aCbMcYYY4wxxhj7QDjoZowxxhhjjDHGPhAOuhljjDHGGGOMsQ/k/wGsz8ivjFGc9wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jHSxaJ82gGWY",
        "4ebi_B7Umalw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}